---
layout: post
title: Neural Machine Translation
excerpt_separator:  <!--more-->
---

# Neural Machine Translation: What is it?

## What is Neural Machine Translation?

NMT is a branch of Machine Translation (No surprises) that with is predecessor SMT (statistical machine translation, part of phrase-based engines) has become the main approach to Machine translation, being one of the most succesful areas 
of application of Deep Learning in Natural Language Processing.

### So how does it work?

A NMT consists of, to dumb it down, two recurrent neural networks connected to each other, a "sequence-to-sequence", or "encoder-to-decoder", is often what it's called. The two networks serve as an autoencoder, which is an artificial neural
network that looks to squeeze input data and then hand it over to the decoder to decompress. The goal is for the output to match the original input, allowing dimensionality reduction to happen. An encoder, like the autoencoder, will compress input sentences, but will create an internal representation to match the compression. The decoder will attempt to decipher the compressed representation, and will train using labels. 



# Research Areas

## Applications

The easiest application of NMT that we use in everyday life is, the most popuplar translator by a long way: Google Translate.


# History

## How it came to be

Prior to 2014, Phrase based statistical machine translation (SMT) systems and Rule-Based machine translation dominated the field. These kinds of methods were effective in creating dictionaries, or grammar programs. Using mormorphological and syntactic rules and semantic analysis of both source and destination languages, RBMT relied on the linguistic aspect of the languages to translate efficiently. RBMT was weak in the sense that it had to be told explicit rules, it cannot cope with various different inputs or inputs with errors. 
SMT on the other hand, uses statistical methods to achieve good results, but rely heavily on massive text corpus datasets, and such corpora are still rare to this day. The larger the corpus, the better the results. 

### Release 

Come 2014, and the first NMT paper was published, followed by the first NMT system in a public translation competition in 2015. By 2016, Google, Microsoft, and Yandex all used NMT, which are some of the best translation software released to date. 

## The Future?

### Related Patents

### References


https://yandex.com/company/blog/one-model-is-better-than-two-yu-yandex-translate-launches-a-hybrid-machine-translation-system/
https://arxiv.org/pdf/1409.0473.pdf
https://arxiv.org/pdf/1802.05368.pdf
https://arxiv.org/pdf/1803.00353.pdf
https://arxiv.org/pdf/1704.06933.pdf
https://machinelearningmastery.com/introduction-neural-machine-translation/
http://blog.systransoft.com/how-does-neural-machine-translation-work/
https://tryolabs.com/blog/2017/12/12/deep-learning-for-nlp-advancements-and-trends-in-2017/
