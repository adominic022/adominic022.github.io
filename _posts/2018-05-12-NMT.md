---
layout: post
title: Neural Machine Translation
excerpt_separator:  <!--more-->
---

# What is it?

## Neural Machine Translation?

NMT is a branch of Machine Translation (No surprises) that with is predecessor SMT (statistical machine translation, part of phrase-based engines) has become the main approach to Machine translation, being one of the most succesful areas of application of Deep Learning in Natural Language Processing.

### So how does it work?

A NMT consists of, to dumb it down, two recurrent neural networks connected to each other, a "sequence-to-sequence", or "encoder-to-decoder", is often what it's called. 

The two networks serve as an autoencoder, which is an artificial neural network that looks to squeeze input data and then hand it over to the decoder to decompress. The goal is for the output to match the original input, allowing dimensionality reduction to happen. An encoder, like the autoencoder, will compress input sentences, but will create an internal representation to match the compression. The decoder will attempt to decipher the compressed representation, and will train using labels. 

![placeholder](https://image.slidesharecdn.com/briefhistoryofneuralmachinetranslation-160812133030/95/brief-history-of-neural-machine-translation-6-638.jpg?cb=1471008729)

# Research Areas

## Applications

![placeholder](https://lh3.googleusercontent.com/fDCN2H5TsP2PiILBb80NQoCwqiiVFnVONer3lqTjwCgdwGHgvD3GmjCLZ6Ybb5hvfmZChNFKhnU=w220-h140-e365)

The easiest application of NMT that we use in everyday life is, the most popuplar translator by a long way: Google Translate. Other uses include Skype's voice translation feature, which is a real-time speech-to-speech translation using Microsoft Translate technology as of 2017. 

Other exciting prospects are wearable, or voice translation devices, a combination of Neural Machine Translation and other Natural Language Processing technology. These device products allow users to speak into a mic that will output into a different language, allowing people more freedom.

# History

## How it came to be

Prior to 2014, Phrase based statistical machine translation (SMT) systems and Rule-Based machine translation dominated the field. These kinds of methods were effective in creating dictionaries, or grammar programs. 

Using mormorphological and syntactic rules and semantic analysis of both source and destination languages, RBMT relied on the linguistic aspect of the languages to translate efficiently. RBMT was weak in the sense that it had to be told explicit rules, it cannot cope with various different inputs or inputs with errors. 

SMT on the other hand, uses statistical methods to achieve good results, but rely heavily on massive text corpus datasets, and such corpora are still rare to this day. The larger the corpus, the better the results. 

### Release 

Come 2014, and the first NMT paper was published, followed by the first NMT system in a public translation competition in 2015. By 2016, Google, Microsoft, and Yandex all used NMT, which are some of the best translation software released to date. 

## The Future?

NMT researchers will most likely now set their focus on training langauges with scrace data; data sets as small as Romanin-English, with only 6 thousand sentances. NMT has shown that it can do extremely well given enough data, but the challenge is in the opposite: focusing on low resource languages and to overcome the limitations that come with it. Recent approaches include zero-shot learning, or applying GAN models with NMT, and etc. 

### Related Patents

 Neural machine translation systems with rare word processing 
https://patentimages.storage.googleapis.com/d3/f1/86/1549ed41bc5c3f/US20160117316A1.pdf

 Using Meta-information in neural machine translation
https://patentimages.storage.googleapis.com/6b/f6/34/51557e8cd013bb/US20170323203A1.pdf

### References


"Company Blog - One Model Is Better than Two. Yandex.Translate Launches a Hybrid Machine Translation System." Yandex. Accessed May 17, 2018. https://yandex.com/company/blog/one-model-is-better-than-two-yu-yandex-translate-launches-a-hybrid-machine-translation-system/.


"A Gentle Introduction to Neural Machine Translation." Machine Learning Mastery. November 21, 2017. Accessed May 17, 2018. https://machinelearningmastery.com/introduction-neural-machine-translation/.


"How Does Neural Machine Translation Work?" Learn About The Latest in Translation News Across The World. Accessed May 17, 2018. http://blog.systransoft.com/how-does-neural-machine-translation-work/.

"Deep Learning for Natural Language Processing (NLP): Advancements & Trends." Tryolabs Blog. December 12, 2017. Accessed May 17, 2018. https://tryolabs.com/blog/2017/12/12/deep-learning-for-nlp-advancements-and-trends-in-2017/.

McDaniel, Annabelle. "Neural Machine Translation for Spoken Language Domains." SlidePlayer. July 03, 2017. Accessed May 17, 2018. http://slideplayer.com/slide/9202214/27/images/14/Neural Machine Translation (NMT).

Dmitry Bahdanau, KyungHyun Cho, Yoshua Bengio. "Neural Machine Translation by Jointly Learning to Align and Translate" Jacobs University Bremen, University de Montreal. 19 May 2016 https://arxiv.org/pdf/1409.0473.pdf

Jiatao Gu, Hany Hassan, Jacob Delvin, Victor O.K Li. "Universal Neural Machine Translation for Extremely Low Resource Languages" University of Hong Kong, Microsoft Research, Google Research. 17 apr 2018. https://arxiv.org/pdf/1802.05368.pdf



