<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-10-16T19:55:28+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">The Nightly Coder</title><subtitle>Coding for Owls and other Nocturnal creatures</subtitle><author><name>Andrew Fong</name></author><entry><title type="html">Machine Learning and Audio</title><link href="http://localhost:4000/2020/10/15/Machine-Learning-and-Audio.html" rel="alternate" type="text/html" title="Machine Learning and Audio" /><published>2020-10-15T00:00:00+09:00</published><updated>2020-10-15T00:00:00+09:00</updated><id>http://localhost:4000/2020/10/15/Machine-Learning-and-Audio</id><content type="html" xml:base="http://localhost:4000/2020/10/15/Machine-Learning-and-Audio.html">&lt;p&gt;Fields:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Audio Classification
The task is essentially to extract features from the audio, and then identify which class the audio belongs to. Many useful applications pertaining to audio classification can be found in the wild – such as genre classification, instrument recognition and artist identification.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A common approach to solve an audio classification task is to pre-process the audio inputs to extract useful features, and then apply a classification algorithm on it. For example, in the case study below we are given a 5 second excerpt of a sound, and the task is to identify which class does it belong to – whether it is a dog barking or a drilling sound. As mentioned in the article, an approach to deal with this is to extract an audio feature called MFCC and then pass it though a neural network to get the appropriate class.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Audio Fingerprinting
The aim of audio fingerprinting is to determine the digital “summary” of the audio. This is done to identify the audio from an audio sample. Shazam is an excellent example of an application of audio fingerprinting. It recognises the music on the basis of the first two to five seconds of a song. However, there are still situations where the system fails, especially where there is a high amount of background noise.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;At a high level, any machine learning problem can be divided into three types of tasks: data tasks (data collection, data cleaning, and feature formation), training (building machine learning models using data features), and evaluation (assessing the model). Features, defined as “individual measurable propert[ies] or characteristic[s] of a phenomenon being observed,” [1] are very useful because they help a machine understand the data and classify it into categories or predict a value.&lt;/p&gt;

&lt;p&gt;Bishop, Christopher (2006). Pattern recognition and machine learning. Berlin: Springer. ISBN 0-387-31073-8.&lt;/p&gt;

&lt;p&gt;What are audio signals?
Audio signals are signals that vibrate in the audible frequency range. When someone talks, it generates air pressure signals; the ear takes in these air pressure differences and communicates with the brain. That’s how the brain helps a person recognize that the signal is speech and understand what someone is saying.&lt;/p&gt;

&lt;p&gt;Data Features &amp;amp; Transformations
mfcc
gfcc
lpcc
pncc
pncc
entropy
Spectrum
spectral centroid
cepstrum
short-term energy
spectral flux
spectral spread
spectral rolloff
spectogram&lt;/p&gt;

&lt;p&gt;Spectrum and cepstrum are two particularly important features in audio processing.
Spectrum &amp;amp; Cepstrum:&lt;/p&gt;

&lt;p&gt;Audio Signal (time domain) -&amp;gt; Fourier Transform (sine &amp;amp; cosine) -&amp;gt;
Spectrum (Signal in the freq domain) -&amp;gt; log magnitude (reduce amplitude diff) -&amp;gt;
inverse fourier transform -&amp;gt; cepstrum&lt;/p&gt;

&lt;p&gt;Mathematically, a spectrum is the Fourier transform of a signal. A Fourier transform converts a time-domain signal to the frequency domain. In other words, a spectrum is the frequency domain representation of the input audio’s time-domain signal.&lt;/p&gt;

&lt;p&gt;A cepstrum is formed by taking the log magnitude of the spectrum followed by an inverse Fourier transform. This results in a signal that’s neither in the frequency domain (because we took an inverse Fourier transform) nor in the time domain (because we took the log magnitude prior to the inverse Fourier transform). The domain of the resulting signal is called the quefrency.&lt;/p&gt;

&lt;p&gt;The reason we care about the signal in the frequency domain relates to the biology of the ear. Many things must happen before we can process and interpret a sound. One happens in the cochlea, a fluid-filled part of the ear with thousands of tiny hairs that are connected to nerves. Some of the hairs are short, and some are relatively longer. The shorter hairs resonate with higher sound frequencies, and the longer hairs resonate with lower sound frequencies. Therefore, the ear is like a natural Fourier transform analyzer!&lt;/p&gt;

&lt;p&gt;Another fact about human hearing is that as the sound frequency increases above 1kHz, our ears begin to get less selective to frequencies. This corresponds well with something called the Mel filter bank.&lt;/p&gt;

&lt;p&gt;MFCC:
Spectrum -&amp;gt; Mel Scale Filter bank -&amp;gt; log magnitude -&amp;gt; Discrete cosine Transform -&amp;gt; MFCC feature&lt;/p&gt;

&lt;p&gt;Passing a spectrum through the Mel filter bank, followed by taking the log magnitude and a discrete cosine transform (DCT) produces the Mel cepstrum. DCT extracts the signal’s main information and peaks. It is also widely used in JPEG and MPEG compressions. The peaks are the gist of the audio information. Typically, the first 13 coefficients extracted from the Mel cepstrum are called the MFCCs. These hold very useful information about audio and are often used to train machine learning models.&lt;/p&gt;

&lt;p&gt;Another filter inspired by human hearing is the Gammatone filter bank. This filter bank is used as a front-end simulation of the cochlea. Thus, it has many applications in speech processing because it aims to replicate how we hear.&lt;/p&gt;

&lt;p&gt;Spectrum -&amp;gt; Gammatone filter bank -&amp;gt; downsample and loudness compression -&amp;gt; discrete cosine transform -&amp;gt; GFCC feature&lt;/p&gt;

&lt;p&gt;GFCCs are formed by passing the spectrum through Gammatone filter bank, followed by loudness compression and DCT. The first (approximately) 22 features are called GFCCs. GFCCs have a number of applications in speech processing, such as speaker identification.&lt;/p&gt;

&lt;p&gt;Other features useful in audio processing tasks (especially speech) include LPCC, BFCC, PNCC, and spectral features like spectral flux, entropy, roll off, centroid, spread, and energy entropy.&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">Fields: Audio Classification The task is essentially to extract features from the audio, and then identify which class the audio belongs to. Many useful applications pertaining to audio classification can be found in the wild – such as genre classification, instrument recognition and artist identification. A common approach to solve an audio classification task is to pre-process the audio inputs to extract useful features, and then apply a classification algorithm on it. For example, in the case study below we are given a 5 second excerpt of a sound, and the task is to identify which class does it belong to – whether it is a dog barking or a drilling sound. As mentioned in the article, an approach to deal with this is to extract an audio feature called MFCC and then pass it though a neural network to get the appropriate class. Audio Fingerprinting The aim of audio fingerprinting is to determine the digital “summary” of the audio. This is done to identify the audio from an audio sample. Shazam is an excellent example of an application of audio fingerprinting. It recognises the music on the basis of the first two to five seconds of a song. However, there are still situations where the system fails, especially where there is a high amount of background noise. At a high level, any machine learning problem can be divided into three types of tasks: data tasks (data collection, data cleaning, and feature formation), training (building machine learning models using data features), and evaluation (assessing the model). Features, defined as “individual measurable propert[ies] or characteristic[s] of a phenomenon being observed,” [1] are very useful because they help a machine understand the data and classify it into categories or predict a value. Bishop, Christopher (2006). Pattern recognition and machine learning. Berlin: Springer. ISBN 0-387-31073-8. What are audio signals? Audio signals are signals that vibrate in the audible frequency range. When someone talks, it generates air pressure signals; the ear takes in these air pressure differences and communicates with the brain. That’s how the brain helps a person recognize that the signal is speech and understand what someone is saying. Data Features &amp;amp; Transformations mfcc gfcc lpcc pncc pncc entropy Spectrum spectral centroid cepstrum short-term energy spectral flux spectral spread spectral rolloff spectogram Spectrum and cepstrum are two particularly important features in audio processing. Spectrum &amp;amp; Cepstrum: Audio Signal (time domain) -&amp;gt; Fourier Transform (sine &amp;amp; cosine) -&amp;gt; Spectrum (Signal in the freq domain) -&amp;gt; log magnitude (reduce amplitude diff) -&amp;gt; inverse fourier transform -&amp;gt; cepstrum Mathematically, a spectrum is the Fourier transform of a signal. A Fourier transform converts a time-domain signal to the frequency domain. In other words, a spectrum is the frequency domain representation of the input audio’s time-domain signal. A cepstrum is formed by taking the log magnitude of the spectrum followed by an inverse Fourier transform. This results in a signal that’s neither in the frequency domain (because we took an inverse Fourier transform) nor in the time domain (because we took the log magnitude prior to the inverse Fourier transform). The domain of the resulting signal is called the quefrency. The reason we care about the signal in the frequency domain relates to the biology of the ear. Many things must happen before we can process and interpret a sound. One happens in the cochlea, a fluid-filled part of the ear with thousands of tiny hairs that are connected to nerves. Some of the hairs are short, and some are relatively longer. The shorter hairs resonate with higher sound frequencies, and the longer hairs resonate with lower sound frequencies. Therefore, the ear is like a natural Fourier transform analyzer! Another fact about human hearing is that as the sound frequency increases above 1kHz, our ears begin to get less selective to frequencies. This corresponds well with something called the Mel filter bank. MFCC: Spectrum -&amp;gt; Mel Scale Filter bank -&amp;gt; log magnitude -&amp;gt; Discrete cosine Transform -&amp;gt; MFCC feature Passing a spectrum through the Mel filter bank, followed by taking the log magnitude and a discrete cosine transform (DCT) produces the Mel cepstrum. DCT extracts the signal’s main information and peaks. It is also widely used in JPEG and MPEG compressions. The peaks are the gist of the audio information. Typically, the first 13 coefficients extracted from the Mel cepstrum are called the MFCCs. These hold very useful information about audio and are often used to train machine learning models. Another filter inspired by human hearing is the Gammatone filter bank. This filter bank is used as a front-end simulation of the cochlea. Thus, it has many applications in speech processing because it aims to replicate how we hear. Spectrum -&amp;gt; Gammatone filter bank -&amp;gt; downsample and loudness compression -&amp;gt; discrete cosine transform -&amp;gt; GFCC feature GFCCs are formed by passing the spectrum through Gammatone filter bank, followed by loudness compression and DCT. The first (approximately) 22 features are called GFCCs. GFCCs have a number of applications in speech processing, such as speaker identification. Other features useful in audio processing tasks (especially speech) include LPCC, BFCC, PNCC, and spectral features like spectral flux, entropy, roll off, centroid, spread, and energy entropy.</summary></entry><entry><title type="html">Sarcasm Detection</title><link href="http://localhost:4000/2018/05/12/Sarcasm-Detection.html" rel="alternate" type="text/html" title="Sarcasm Detection" /><published>2018-05-12T00:00:00+09:00</published><updated>2018-05-12T00:00:00+09:00</updated><id>http://localhost:4000/2018/05/12/Sarcasm-Detection</id><content type="html" xml:base="http://localhost:4000/2018/05/12/Sarcasm-Detection.html">&lt;h2 id=&quot;sarcasm&quot;&gt;Sarcasm?&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Sarcasm&lt;/em&gt; is a linguistic phenomenon in which people state  the opposite of what they actually mean. Common in literature and in spoken words, it is the use of irony to convey one’s resentment or to mock.&lt;/p&gt;

&lt;p&gt;While banter is good-humored and more of a playful conversation of sorts, sarcasm is sharp: it is meant to hurt and otherwise mock with irony.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://blogs.nvidia.com/wp-content/uploads/2018/01/twitter-taggedsarcasm2.png&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;so-how-does-it-work&quot;&gt;So how does it work?&lt;/h1&gt;

&lt;h2 id=&quot;its-pretty-hard&quot;&gt;It’s pretty hard&lt;/h2&gt;

&lt;p&gt;Sarcasm is definitely on the farther end of difficulty when it comes to human expression. It’s difficult for humans to understand, let alone computers. Humans are used to using tone of voice and expression, or emoticons and hashtags on social media to relay their sarcasm to their readers/listeners.&lt;/p&gt;

&lt;p&gt;Another fact that makes it difficult is the use of conversational and situation context, as well as, well, common sense and general knowledge of the world. This of course, makes teaching AI unique human linguistic traits just &lt;em&gt; wonderfull&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Both problems are a &lt;strong&gt;Classification&lt;/strong&gt; problem. When given a piece of text as input, we want to guess if it is of sarcastic quality.&lt;/p&gt;

&lt;h2 id=&quot;approaches--methods&quot;&gt;Approaches &amp;amp; Methods&lt;/h2&gt;

&lt;h3 id=&quot;rule-based&quot;&gt;Rule Based&lt;/h3&gt;
&lt;p&gt;Rule-based approaches attempt to identify sarcasm through specific evidences. These evidences are captured in terms of rules that rely on indicators of sarcasm. They  use  Google  search  in  order  to  determine  how  likely  a simile is. They present a 9-step approach where at each step/rule, a simile is validated using the number of search results. A strength of this approach is that they present an
error analysis corresponding to multiple rules.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://image.slidesharecdn.com/cs626-sarcasmandthwarting-nov13-131115101715-phpapp02/95/sarcasm-thwarting-in-sentiment-analysis-iitbombay-30-638.jpg?cb=1384510712&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hashtags are often used by  tweet  authors  to  highlight  sarcasm,  and  hence,  if  the  sentiment  expressed  by  a
hashtag does not agree with rest of the tweet, the tweet is predicted as sarcastic.&lt;/p&gt;

&lt;p&gt;The first uses a parse–based lexicon generation algorithm that creates parse trees of sentences and identifies situation phrases that bear sentiment. If a negative phrase occurs in a positive sentence, it is predicted as sarcastic.&lt;/p&gt;

&lt;h4 id=&quot;statistical&quot;&gt;Statistical&lt;/h4&gt;
&lt;p&gt;A variety of classifiers have been experimented for sarcasm
detection. Most work in sarcasm detection relies on SVM, with sequential minimal optimization and linear regression. Other approaches include using Chi-squared for identifying discriminating features, or Naive-Bayes combined with SVM for labeling features.&lt;/p&gt;

&lt;h3 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h3&gt;
&lt;p&gt;similarity between word embeddings as features for sarcasm detection.
They augment features based on similarity of word embeddings related to most con-gruent and incongruent word pairs, and report an improvement in performance. The augmentation is key because they observe that using these features alone does not suffice.&lt;/p&gt;

&lt;p&gt;Combinations of convolutional neural network,
LSTM followed by a DNN are the usual approaches taken. They compare their approach against recursive SVM, and show an improvement in case of deep learning architecture.&lt;/p&gt;

&lt;h2 id=&quot;history&quot;&gt;History&lt;/h2&gt;
&lt;p&gt;First paper on sarcasm detection featured in 2006, with study of lexicon indicators becoming popular the following year. 
Discovering sarcastic patterns was an early trend in sarcasm detection. Several approaches dealt with extracting patterns that are indicative of sarcasm, or carry implied sentiment. These patterns may then be used as features for a statistical classifier, or as rules in a rule-based classifier.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://qph.fs.quoracdn.net/main-qimg-a6aeed99e114164f365212053447cfb7-c&quot; alt=&quot;placeholder&quot; /&gt;
Using Twitter Hashtags as labels for twitter datasets became popular around 2013, with it being an easy label to use. This can be commonly seen in other papers, but has often problems due to complex type of sarcasm used in tweets.&lt;/p&gt;

&lt;h3 id=&quot;present&quot;&gt;Present&lt;/h3&gt;
&lt;p&gt;A recent trend in sarcasm detection is the use of context. The term context here refers to any information beyond the text to be predicted, and beyond common knowledge. Context may be incorporated in a variety of ways, using it as supplementary data or information from the source to improve results and learning.&lt;/p&gt;

&lt;h1 id=&quot;issues&quot;&gt;Issues&lt;/h1&gt;
&lt;p&gt;Sarcasm detection suffors from 3 main problems: data, feature, and classification. Although hashtag-based labeling can provide large-scale supervision, the quality of the dataset may become doubtful. This is particularly true in case of use of #not to indicate insincere sentiment.&lt;br /&gt;
For example,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I totally love bland food. #not”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The speaker expresses sarcasm through #not. In most reported works that use hashtag-based supervision, the hashtag is removed in the pre-processing step. This reduces the sentence above to 
’I love bland food’ - which may not have a sarcastic interpretation, unless author’s context is incorporated.&lt;/p&gt;

&lt;p&gt;Another feature that is often an issue is the question that can sentiment be used to detect sarcasm. The motivation behind sarcasm detection is often pointed as sarcastic sentences misleading a sentiment classifier. However, several approaches use sentiment as an input to the sarcasm classifier. It must, however, be noted that these approaches require the sentiment polarity of a sentence.&lt;/p&gt;

&lt;p&gt;Sarcasm is an infrequent phenomenon of sentiment expression. This skew also reflects in datasets.&lt;/p&gt;

&lt;h1 id=&quot;the-future&quot;&gt;The Future&lt;/h1&gt;

&lt;h3 id=&quot;coverage-of-different-forms-of-sarcasm&quot;&gt;Coverage of different forms of sarcasm&lt;/h3&gt;
&lt;p&gt;we described four species of sarcasm: propositional, lexical, like-prefixed and illocutionary sarcasm. We observe that current approaches are limited in handling the last two forms of sar-
casm:  like-prefixed  and  illocutionary.  Future  work  may  focus  on  these  forms  of sarcasm.&lt;/p&gt;

&lt;h3 id=&quot;culture-specific-aspects-of-sarcasm-detection&quot;&gt;Culture-specific aspects of sarcasm detection&lt;/h3&gt;
&lt;p&gt;sarcasm is closely related to language/culture-specific traits. Future approaches to sarcasm detection in new languages will benefit from understanding such traits, and  incorporating  them  into  their  classification  frameworks. show that American and Indian annotators may have substantial disagreement in their sarcasm annotations - however, this sees a non-significant degradation in the
performance of sarcasm detection
&lt;img src=&quot;https://sg.malverninternational.com/wp-content/uploads/2017/01/languages.png&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deep-learning-based-architectures&quot;&gt;Deep learning-based architectures&lt;/h3&gt;
&lt;p&gt;Very few approaches have explored deep learning-based architectures so far. Future work that uses these architecture may show promise.&lt;/p&gt;

&lt;h2 id=&quot;related-companies&quot;&gt;Related Companies&lt;/h2&gt;
&lt;p&gt;Twitter is an obvious candidate, as are any other huge big data companies. Applications of Sarcasm Detection include: Sentiment analysis, opinion mining, and advertisement.&lt;/p&gt;

&lt;h3 id=&quot;related-patents&quot;&gt;Related patents&lt;/h3&gt;
&lt;p&gt;https://patents.google.com/patent/US6638217B1/en&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;p&gt;Aditya Joshi, Pushpak Bhattacharya, Mark J Carman. “Automatic Sarcasm Detection: A Survey.” IITB-Monash Research Academy, Indian Institute of Technology Bombay, Monash University. 20 Sep 2016. https://arxiv.org/pdf/1602.03426.pdf&lt;/p&gt;

&lt;p&gt;Commentary. “Teaching AI How to Be Sarcastic Is Totally the Easiest Thing Ever.” Quartz. October 06, 2016. Accessed May 17, 2018. https://qz.com/801813/teaching-ai-how-to-be-sarcastic-is-totally-the-easiest-thing-ever/.&lt;/p&gt;

&lt;p&gt;Komalpreet Kaur Bindra, Ankita Gupta. “Tweet Sarcasm: Mechanism of Sarcasm Detection in Twitter” PEC University of Technology, Chandigarh, India. https://pdfs.semanticscholar.org/f1a1/949aab6d40372e0a025fe8f135c220ca0ca3.pdf&lt;/p&gt;

&lt;p&gt;Diana Mayndard, Mark A. Greenwood. “Who cares about sarcastic tweets? Investigating the impact of sarcasm onsentiment analysis” University of Sheffield.  https://gate.ac.uk/sale/lrec2014/arcomem/sarcasm.pdf&lt;/p&gt;

&lt;p&gt;Silvio Amir, Byron C. Wallace, Hao Lyu, Paula Carvalho, Mario J. Silva. “Modelling Context with User Embeddings for Sarcasm Detection in Social Media” INESC-ID Lisboa, Instituto Superior Tecnico, Universidade de Lisboa iSchool, University of Texas at Austin. 5 Jul 2016https://arxiv.org/pdf/1607.00976.pdf&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">Sarcasm? Sarcasm is a linguistic phenomenon in which people state the opposite of what they actually mean. Common in literature and in spoken words, it is the use of irony to convey one’s resentment or to mock. While banter is good-humored and more of a playful conversation of sorts, sarcasm is sharp: it is meant to hurt and otherwise mock with irony. So how does it work? It’s pretty hard Sarcasm is definitely on the farther end of difficulty when it comes to human expression. It’s difficult for humans to understand, let alone computers. Humans are used to using tone of voice and expression, or emoticons and hashtags on social media to relay their sarcasm to their readers/listeners. Another fact that makes it difficult is the use of conversational and situation context, as well as, well, common sense and general knowledge of the world. This of course, makes teaching AI unique human linguistic traits just wonderfull. Both problems are a Classification problem. When given a piece of text as input, we want to guess if it is of sarcastic quality. Approaches &amp;amp; Methods Rule Based Rule-based approaches attempt to identify sarcasm through specific evidences. These evidences are captured in terms of rules that rely on indicators of sarcasm. They use Google search in order to determine how likely a simile is. They present a 9-step approach where at each step/rule, a simile is validated using the number of search results. A strength of this approach is that they present an error analysis corresponding to multiple rules. Hashtags are often used by tweet authors to highlight sarcasm, and hence, if the sentiment expressed by a hashtag does not agree with rest of the tweet, the tweet is predicted as sarcastic. The first uses a parse–based lexicon generation algorithm that creates parse trees of sentences and identifies situation phrases that bear sentiment. If a negative phrase occurs in a positive sentence, it is predicted as sarcastic. Statistical A variety of classifiers have been experimented for sarcasm detection. Most work in sarcasm detection relies on SVM, with sequential minimal optimization and linear regression. Other approaches include using Chi-squared for identifying discriminating features, or Naive-Bayes combined with SVM for labeling features. Machine Learning similarity between word embeddings as features for sarcasm detection. They augment features based on similarity of word embeddings related to most con-gruent and incongruent word pairs, and report an improvement in performance. The augmentation is key because they observe that using these features alone does not suffice. Combinations of convolutional neural network, LSTM followed by a DNN are the usual approaches taken. They compare their approach against recursive SVM, and show an improvement in case of deep learning architecture. History First paper on sarcasm detection featured in 2006, with study of lexicon indicators becoming popular the following year. Discovering sarcastic patterns was an early trend in sarcasm detection. Several approaches dealt with extracting patterns that are indicative of sarcasm, or carry implied sentiment. These patterns may then be used as features for a statistical classifier, or as rules in a rule-based classifier. Using Twitter Hashtags as labels for twitter datasets became popular around 2013, with it being an easy label to use. This can be commonly seen in other papers, but has often problems due to complex type of sarcasm used in tweets. Present A recent trend in sarcasm detection is the use of context. The term context here refers to any information beyond the text to be predicted, and beyond common knowledge. Context may be incorporated in a variety of ways, using it as supplementary data or information from the source to improve results and learning. Issues Sarcasm detection suffors from 3 main problems: data, feature, and classification. Although hashtag-based labeling can provide large-scale supervision, the quality of the dataset may become doubtful. This is particularly true in case of use of #not to indicate insincere sentiment. For example, “I totally love bland food. #not” The speaker expresses sarcasm through #not. In most reported works that use hashtag-based supervision, the hashtag is removed in the pre-processing step. This reduces the sentence above to ’I love bland food’ - which may not have a sarcastic interpretation, unless author’s context is incorporated. Another feature that is often an issue is the question that can sentiment be used to detect sarcasm. The motivation behind sarcasm detection is often pointed as sarcastic sentences misleading a sentiment classifier. However, several approaches use sentiment as an input to the sarcasm classifier. It must, however, be noted that these approaches require the sentiment polarity of a sentence. Sarcasm is an infrequent phenomenon of sentiment expression. This skew also reflects in datasets. The Future Coverage of different forms of sarcasm we described four species of sarcasm: propositional, lexical, like-prefixed and illocutionary sarcasm. We observe that current approaches are limited in handling the last two forms of sar- casm: like-prefixed and illocutionary. Future work may focus on these forms of sarcasm. Culture-specific aspects of sarcasm detection sarcasm is closely related to language/culture-specific traits. Future approaches to sarcasm detection in new languages will benefit from understanding such traits, and incorporating them into their classification frameworks. show that American and Indian annotators may have substantial disagreement in their sarcasm annotations - however, this sees a non-significant degradation in the performance of sarcasm detection Deep learning-based architectures Very few approaches have explored deep learning-based architectures so far. Future work that uses these architecture may show promise. Related Companies Twitter is an obvious candidate, as are any other huge big data companies. Applications of Sarcasm Detection include: Sentiment analysis, opinion mining, and advertisement. Related patents https://patents.google.com/patent/US6638217B1/en Reference Aditya Joshi, Pushpak Bhattacharya, Mark J Carman. “Automatic Sarcasm Detection: A Survey.” IITB-Monash Research Academy, Indian Institute of Technology Bombay, Monash University. 20 Sep 2016. https://arxiv.org/pdf/1602.03426.pdf Commentary. “Teaching AI How to Be Sarcastic Is Totally the Easiest Thing Ever.” Quartz. October 06, 2016. Accessed May 17, 2018. https://qz.com/801813/teaching-ai-how-to-be-sarcastic-is-totally-the-easiest-thing-ever/. Komalpreet Kaur Bindra, Ankita Gupta. “Tweet Sarcasm: Mechanism of Sarcasm Detection in Twitter” PEC University of Technology, Chandigarh, India. https://pdfs.semanticscholar.org/f1a1/949aab6d40372e0a025fe8f135c220ca0ca3.pdf Diana Mayndard, Mark A. Greenwood. “Who cares about sarcastic tweets? Investigating the impact of sarcasm onsentiment analysis” University of Sheffield. https://gate.ac.uk/sale/lrec2014/arcomem/sarcasm.pdf Silvio Amir, Byron C. Wallace, Hao Lyu, Paula Carvalho, Mario J. Silva. “Modelling Context with User Embeddings for Sarcasm Detection in Social Media” INESC-ID Lisboa, Instituto Superior Tecnico, Universidade de Lisboa iSchool, University of Texas at Austin. 5 Jul 2016https://arxiv.org/pdf/1607.00976.pdf</summary></entry><entry><title type="html">Neural Machine Translation</title><link href="http://localhost:4000/2018/05/12/NMT.html" rel="alternate" type="text/html" title="Neural Machine Translation" /><published>2018-05-12T00:00:00+09:00</published><updated>2018-05-12T00:00:00+09:00</updated><id>http://localhost:4000/2018/05/12/NMT</id><content type="html" xml:base="http://localhost:4000/2018/05/12/NMT.html">&lt;h1 id=&quot;what-is-it&quot;&gt;What is it?&lt;/h1&gt;

&lt;h2 id=&quot;neural-machine-translation&quot;&gt;Neural Machine Translation?&lt;/h2&gt;

&lt;p&gt;NMT is a branch of Machine Translation (No surprises) that with is predecessor SMT (statistical machine translation, part of phrase-based engines) has become the main approach to Machine translation, being one of the most succesful areas of application of Deep Learning in Natural Language Processing.&lt;/p&gt;

&lt;h3 id=&quot;so-how-does-it-work&quot;&gt;So how does it work?&lt;/h3&gt;

&lt;p&gt;A NMT consists of, to dumb it down, two recurrent neural networks connected to each other, a “sequence-to-sequence”, or “encoder-to-decoder”, is often what it’s called.&lt;/p&gt;

&lt;p&gt;The two networks serve as an autoencoder, which is an artificial neural network that looks to squeeze input data and then hand it over to the decoder to decompress. The goal is for the output to match the original input, allowing dimensionality reduction to happen. An encoder, like the autoencoder, will compress input sentences, but will create an internal representation to match the compression. The decoder will attempt to decipher the compressed representation, and will train using labels.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://image.slidesharecdn.com/briefhistoryofneuralmachinetranslation-160812133030/95/brief-history-of-neural-machine-translation-6-638.jpg?cb=1471008729&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;research-areas&quot;&gt;Research Areas&lt;/h1&gt;

&lt;h2 id=&quot;applications&quot;&gt;Applications&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/fDCN2H5TsP2PiILBb80NQoCwqiiVFnVONer3lqTjwCgdwGHgvD3GmjCLZ6Ybb5hvfmZChNFKhnU=w220-h140-e365&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The easiest application of NMT that we use in everyday life is, the most popuplar translator by a long way: Google Translate. Other uses include Skype’s voice translation feature, which is a real-time speech-to-speech translation using Microsoft Translate technology as of 2017.&lt;/p&gt;

&lt;p&gt;Other exciting prospects are wearable, or voice translation devices, a combination of Neural Machine Translation and other Natural Language Processing technology. These device products allow users to speak into a mic that will output into a different language, allowing people more freedom.&lt;/p&gt;

&lt;h1 id=&quot;history&quot;&gt;History&lt;/h1&gt;

&lt;h2 id=&quot;how-it-came-to-be&quot;&gt;How it came to be&lt;/h2&gt;

&lt;p&gt;Prior to 2014, Phrase based statistical machine translation (SMT) systems and Rule-Based machine translation dominated the field. These kinds of methods were effective in creating dictionaries, or grammar programs.&lt;/p&gt;

&lt;p&gt;Using mormorphological and syntactic rules and semantic analysis of both source and destination languages, RBMT relied on the linguistic aspect of the languages to translate efficiently. RBMT was weak in the sense that it had to be told explicit rules, it cannot cope with various different inputs or inputs with errors.&lt;/p&gt;

&lt;p&gt;SMT on the other hand, uses statistical methods to achieve good results, but rely heavily on massive text corpus datasets, and such corpora are still rare to this day. The larger the corpus, the better the results.&lt;/p&gt;

&lt;h3 id=&quot;release&quot;&gt;Release&lt;/h3&gt;

&lt;p&gt;Come 2014, and the first NMT paper was published, followed by the first NMT system in a public translation competition in 2015. By 2016, Google, Microsoft, and Yandex all used NMT, which are some of the best translation software released to date.&lt;/p&gt;

&lt;h2 id=&quot;the-future&quot;&gt;The Future?&lt;/h2&gt;

&lt;p&gt;NMT researchers will most likely now set their focus on training langauges with scrace data; data sets as small as Romanin-English, with only 6 thousand sentances. NMT has shown that it can do extremely well given enough data, but the challenge is in the opposite: focusing on low resource languages and to overcome the limitations that come with it. Recent approaches include zero-shot learning, or applying GAN models with NMT, and etc.&lt;/p&gt;

&lt;h3 id=&quot;related-patents&quot;&gt;Related Patents&lt;/h3&gt;

&lt;p&gt;Neural machine translation systems with rare word processing 
https://patentimages.storage.googleapis.com/d3/f1/86/1549ed41bc5c3f/US20160117316A1.pdf&lt;/p&gt;

&lt;p&gt;Using Meta-information in neural machine translation
https://patentimages.storage.googleapis.com/6b/f6/34/51557e8cd013bb/US20170323203A1.pdf&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;“Company Blog - One Model Is Better than Two. Yandex.Translate Launches a Hybrid Machine Translation System.” Yandex. Accessed May 17, 2018. https://yandex.com/company/blog/one-model-is-better-than-two-yu-yandex-translate-launches-a-hybrid-machine-translation-system/.&lt;/p&gt;

&lt;p&gt;“A Gentle Introduction to Neural Machine Translation.” Machine Learning Mastery. November 21, 2017. Accessed May 17, 2018. https://machinelearningmastery.com/introduction-neural-machine-translation/.&lt;/p&gt;

&lt;p&gt;“How Does Neural Machine Translation Work?” Learn About The Latest in Translation News Across The World. Accessed May 17, 2018. http://blog.systransoft.com/how-does-neural-machine-translation-work/.&lt;/p&gt;

&lt;p&gt;“Deep Learning for Natural Language Processing (NLP): Advancements &amp;amp; Trends.” Tryolabs Blog. December 12, 2017. Accessed May 17, 2018. https://tryolabs.com/blog/2017/12/12/deep-learning-for-nlp-advancements-and-trends-in-2017/.&lt;/p&gt;

&lt;p&gt;McDaniel, Annabelle. “Neural Machine Translation for Spoken Language Domains.” SlidePlayer. July 03, 2017. Accessed May 17, 2018. http://slideplayer.com/slide/9202214/27/images/14/Neural Machine Translation (NMT).&lt;/p&gt;

&lt;p&gt;Dmitry Bahdanau, KyungHyun Cho, Yoshua Bengio. “Neural Machine Translation by Jointly Learning to Align and Translate” Jacobs University Bremen, University de Montreal. 19 May 2016 https://arxiv.org/pdf/1409.0473.pdf&lt;/p&gt;

&lt;p&gt;Jiatao Gu, Hany Hassan, Jacob Delvin, Victor O.K Li. “Universal Neural Machine Translation for Extremely Low Resource Languages” University of Hong Kong, Microsoft Research, Google Research. 17 apr 2018. https://arxiv.org/pdf/1802.05368.pdf&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">What is it? Neural Machine Translation? NMT is a branch of Machine Translation (No surprises) that with is predecessor SMT (statistical machine translation, part of phrase-based engines) has become the main approach to Machine translation, being one of the most succesful areas of application of Deep Learning in Natural Language Processing. So how does it work? A NMT consists of, to dumb it down, two recurrent neural networks connected to each other, a “sequence-to-sequence”, or “encoder-to-decoder”, is often what it’s called. The two networks serve as an autoencoder, which is an artificial neural network that looks to squeeze input data and then hand it over to the decoder to decompress. The goal is for the output to match the original input, allowing dimensionality reduction to happen. An encoder, like the autoencoder, will compress input sentences, but will create an internal representation to match the compression. The decoder will attempt to decipher the compressed representation, and will train using labels. Research Areas Applications The easiest application of NMT that we use in everyday life is, the most popuplar translator by a long way: Google Translate. Other uses include Skype’s voice translation feature, which is a real-time speech-to-speech translation using Microsoft Translate technology as of 2017. Other exciting prospects are wearable, or voice translation devices, a combination of Neural Machine Translation and other Natural Language Processing technology. These device products allow users to speak into a mic that will output into a different language, allowing people more freedom. History How it came to be Prior to 2014, Phrase based statistical machine translation (SMT) systems and Rule-Based machine translation dominated the field. These kinds of methods were effective in creating dictionaries, or grammar programs. Using mormorphological and syntactic rules and semantic analysis of both source and destination languages, RBMT relied on the linguistic aspect of the languages to translate efficiently. RBMT was weak in the sense that it had to be told explicit rules, it cannot cope with various different inputs or inputs with errors. SMT on the other hand, uses statistical methods to achieve good results, but rely heavily on massive text corpus datasets, and such corpora are still rare to this day. The larger the corpus, the better the results. Release Come 2014, and the first NMT paper was published, followed by the first NMT system in a public translation competition in 2015. By 2016, Google, Microsoft, and Yandex all used NMT, which are some of the best translation software released to date. The Future? NMT researchers will most likely now set their focus on training langauges with scrace data; data sets as small as Romanin-English, with only 6 thousand sentances. NMT has shown that it can do extremely well given enough data, but the challenge is in the opposite: focusing on low resource languages and to overcome the limitations that come with it. Recent approaches include zero-shot learning, or applying GAN models with NMT, and etc. Related Patents Neural machine translation systems with rare word processing https://patentimages.storage.googleapis.com/d3/f1/86/1549ed41bc5c3f/US20160117316A1.pdf Using Meta-information in neural machine translation https://patentimages.storage.googleapis.com/6b/f6/34/51557e8cd013bb/US20170323203A1.pdf References “Company Blog - One Model Is Better than Two. Yandex.Translate Launches a Hybrid Machine Translation System.” Yandex. Accessed May 17, 2018. https://yandex.com/company/blog/one-model-is-better-than-two-yu-yandex-translate-launches-a-hybrid-machine-translation-system/. “A Gentle Introduction to Neural Machine Translation.” Machine Learning Mastery. November 21, 2017. Accessed May 17, 2018. https://machinelearningmastery.com/introduction-neural-machine-translation/. “How Does Neural Machine Translation Work?” Learn About The Latest in Translation News Across The World. Accessed May 17, 2018. http://blog.systransoft.com/how-does-neural-machine-translation-work/. “Deep Learning for Natural Language Processing (NLP): Advancements &amp;amp; Trends.” Tryolabs Blog. December 12, 2017. Accessed May 17, 2018. https://tryolabs.com/blog/2017/12/12/deep-learning-for-nlp-advancements-and-trends-in-2017/. McDaniel, Annabelle. “Neural Machine Translation for Spoken Language Domains.” SlidePlayer. July 03, 2017. Accessed May 17, 2018. http://slideplayer.com/slide/9202214/27/images/14/Neural Machine Translation (NMT). Dmitry Bahdanau, KyungHyun Cho, Yoshua Bengio. “Neural Machine Translation by Jointly Learning to Align and Translate” Jacobs University Bremen, University de Montreal. 19 May 2016 https://arxiv.org/pdf/1409.0473.pdf Jiatao Gu, Hany Hassan, Jacob Delvin, Victor O.K Li. “Universal Neural Machine Translation for Extremely Low Resource Languages” University of Hong Kong, Microsoft Research, Google Research. 17 apr 2018. https://arxiv.org/pdf/1802.05368.pdf</summary></entry><entry><title type="html">Acoustic Signal Processing</title><link href="http://localhost:4000/2018/05/12/Acoustic-Signal-Processing.html" rel="alternate" type="text/html" title="Acoustic Signal Processing" /><published>2018-05-12T00:00:00+09:00</published><updated>2018-05-12T00:00:00+09:00</updated><id>http://localhost:4000/2018/05/12/Acoustic-Signal-Processing</id><content type="html" xml:base="http://localhost:4000/2018/05/12/Acoustic-Signal-Processing.html">&lt;h1 id=&quot;signal-processing-introduction&quot;&gt;Signal Processing: Introduction&lt;/h1&gt;

&lt;p&gt;Signal processing refers to the acquisition, storage, display, and generation of signals – also to the extraction of information from signals and the re-encoding of information. As such, signal processing in some form is an essential element in the practice of all aspects of acoustics. Signal processing algorithms enable acousticians to separate signals from noise, to perform automatic speech recognition, or to compress information for more efficient storage or transmission.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.allaboutcircuits.com/uploads/articles/An-Introduction-to-Digital-Signal-Processing-(3).png&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;acoustics-digital&quot;&gt;Acoustics? Digital?&lt;/h3&gt;

&lt;p&gt;Acoustics, or Audio signal processing, is intentional alteration of audio signals, electronically represented as a digital/analog form that can later be processed as signals. Before digital technology came along, analog (read continuous) signals were commonly used, in things like radio broadcasting and such. These were derived from control systems back in the 1940s and 50s.&lt;/p&gt;

&lt;p&gt;However, as times changed, and computers/software more affordable, digital signals were preferred. Basic applications include: efficient storage, compression, transmission, enhancement. However, recent introduction of Neural Networks, Statistical Vector Machines, and other statistical approaches have led to more interesting aspects of application. Areas of music, speech, and environmental sounds have become the hottest topics to date.&lt;/p&gt;

&lt;h2 id=&quot;applications&quot;&gt;Applications&lt;/h2&gt;

&lt;h4 id=&quot;classification&quot;&gt;Classification&lt;/h4&gt;

&lt;p&gt;Audio classification is a fundamental problem in the field of audio processing. The task is essentially to extract features from the audio, and then identify which class the audio belongs to. Many useful applications pertaining to audio classification can be found in the wild – such as genre classification, instrument recognition and artist identification.&lt;/p&gt;

&lt;p&gt;A common approach to solve an audio classification task is to pre-process the audio inputs to extract useful features, and then apply a classification algorithm on it. For example, in the case study below we are given a 5 second excerpt of a sound, and the task is to identify which class does it belong to – whether it is a dog barking or a drilling sound. As mentioned in the article, an approach to deal with this is to extract an audio feature called MFCC and then pass it though a neural network to get the appropriate class.&lt;/p&gt;

&lt;h4 id=&quot;fingerprinting&quot;&gt;Fingerprinting&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://icdn3.digitaltrends.com/image/shazam-app-720x720.jpg?ver=1.jpg&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The aim of audio fingerprinting is to determine the digital “summary” of the audio. This is done to identify the audio from an audio sample. Shazam is an excellent example of an application of audio fingerprinting. It recognises the music on the basis of the first two to five seconds of a song. However, there are still situations where the system fails, especially where there is a high amount of background noise.&lt;/p&gt;

&lt;p&gt;To solve this problem, an approach could be to represent the audio in a different manner, so that it is easily deciphered. Then, we can find out the patterns that differentiate the audio from the background noise. In the case study below, the author converts raw audio to spectrograms and then uses peak finding and fingerprint hashing algorithms to define the fingerprints of that audio file.&lt;/p&gt;

&lt;h4 id=&quot;music-transcription&quot;&gt;Music Transcription&lt;/h4&gt;

&lt;p&gt;Music Transcription is another challenging audio processing task. It comprises of annotating audio and creating a kind of “sheet” for generating music from it at a later point of time. The manual effort involved in transcribing music from recordings can be vast. It varies enormously depending on the complexity of the music, how good our listening skills are and how detailed we want our transcription to be.
The approach for music transcription is similar to that of speech recognition, where musical notes are transcribed into lyrical excerpts of instruments.&lt;/p&gt;

&lt;h2 id=&quot;related-companies&quot;&gt;Related Companies&lt;/h2&gt;

&lt;p&gt;Audio Signal processing, as part of signal processing, is essential in numerous technology, and is much common in technology today. Most of the applications are hybrids, as in they are a used in a combination with another technology as a product. An easy example would be any application that uses voice recognition software, such as Baidu, Google’s Duplex, Cortana, Alexa, etc.&lt;/p&gt;

&lt;h3 id=&quot;related-patents&quot;&gt;Related Patents&lt;/h3&gt;
&lt;p&gt;https://patents.google.com/patent/US9275648B2/en&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;Derek J. Ross, Bird Call Recognition with Artificial Neural Networks, Support Vector Machines, and Kernel Density Estimation. (Winnipeg, Canada, 2006). http://www.antiquark.com/thesis/msc-thesis-derek-ross-v5c.pdf&lt;/p&gt;

&lt;p&gt;“Audio Signal Processing for Music Applications.” Coursera. Accessed May 17, 2018. https://www.coursera.org/learn/audio-signal-processing.&lt;/p&gt;

&lt;p&gt;Tzanetakis, George. “George Tzanetakis.” UVic Learn to Code. Accessed May 17, 2018. http://webhome.csc.uvic.ca/~gtzan/output/.&lt;/p&gt;

&lt;p&gt;Duan, Shufei, Jinglan Zhang, Paul Roe, and Michael Towsey. “A Survey of Tagging Techniques for Music, Speech and Environmental Sound.” SpringerLink. October 25, 2012. Accessed May 17, 2018. https://link.springer.com/article/10.1007/s10462-012-9362-y.&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">Signal Processing: Introduction Signal processing refers to the acquisition, storage, display, and generation of signals – also to the extraction of information from signals and the re-encoding of information. As such, signal processing in some form is an essential element in the practice of all aspects of acoustics. Signal processing algorithms enable acousticians to separate signals from noise, to perform automatic speech recognition, or to compress information for more efficient storage or transmission. Acoustics? Digital? Acoustics, or Audio signal processing, is intentional alteration of audio signals, electronically represented as a digital/analog form that can later be processed as signals. Before digital technology came along, analog (read continuous) signals were commonly used, in things like radio broadcasting and such. These were derived from control systems back in the 1940s and 50s. However, as times changed, and computers/software more affordable, digital signals were preferred. Basic applications include: efficient storage, compression, transmission, enhancement. However, recent introduction of Neural Networks, Statistical Vector Machines, and other statistical approaches have led to more interesting aspects of application. Areas of music, speech, and environmental sounds have become the hottest topics to date. Applications Classification Audio classification is a fundamental problem in the field of audio processing. The task is essentially to extract features from the audio, and then identify which class the audio belongs to. Many useful applications pertaining to audio classification can be found in the wild – such as genre classification, instrument recognition and artist identification. A common approach to solve an audio classification task is to pre-process the audio inputs to extract useful features, and then apply a classification algorithm on it. For example, in the case study below we are given a 5 second excerpt of a sound, and the task is to identify which class does it belong to – whether it is a dog barking or a drilling sound. As mentioned in the article, an approach to deal with this is to extract an audio feature called MFCC and then pass it though a neural network to get the appropriate class. Fingerprinting The aim of audio fingerprinting is to determine the digital “summary” of the audio. This is done to identify the audio from an audio sample. Shazam is an excellent example of an application of audio fingerprinting. It recognises the music on the basis of the first two to five seconds of a song. However, there are still situations where the system fails, especially where there is a high amount of background noise. To solve this problem, an approach could be to represent the audio in a different manner, so that it is easily deciphered. Then, we can find out the patterns that differentiate the audio from the background noise. In the case study below, the author converts raw audio to spectrograms and then uses peak finding and fingerprint hashing algorithms to define the fingerprints of that audio file. Music Transcription Music Transcription is another challenging audio processing task. It comprises of annotating audio and creating a kind of “sheet” for generating music from it at a later point of time. The manual effort involved in transcribing music from recordings can be vast. It varies enormously depending on the complexity of the music, how good our listening skills are and how detailed we want our transcription to be. The approach for music transcription is similar to that of speech recognition, where musical notes are transcribed into lyrical excerpts of instruments. Related Companies Audio Signal processing, as part of signal processing, is essential in numerous technology, and is much common in technology today. Most of the applications are hybrids, as in they are a used in a combination with another technology as a product. An easy example would be any application that uses voice recognition software, such as Baidu, Google’s Duplex, Cortana, Alexa, etc. Related Patents https://patents.google.com/patent/US9275648B2/en References Derek J. Ross, Bird Call Recognition with Artificial Neural Networks, Support Vector Machines, and Kernel Density Estimation. (Winnipeg, Canada, 2006). http://www.antiquark.com/thesis/msc-thesis-derek-ross-v5c.pdf “Audio Signal Processing for Music Applications.” Coursera. Accessed May 17, 2018. https://www.coursera.org/learn/audio-signal-processing. Tzanetakis, George. “George Tzanetakis.” UVic Learn to Code. Accessed May 17, 2018. http://webhome.csc.uvic.ca/~gtzan/output/. Duan, Shufei, Jinglan Zhang, Paul Roe, and Michael Towsey. “A Survey of Tagging Techniques for Music, Speech and Environmental Sound.” SpringerLink. October 25, 2012. Accessed May 17, 2018. https://link.springer.com/article/10.1007/s10462-012-9362-y.</summary></entry><entry><title type="html">Iris AI</title><link href="http://localhost:4000/2018/04/03/Iris-AI-02.html" rel="alternate" type="text/html" title="Iris AI" /><published>2018-04-03T00:00:00+09:00</published><updated>2018-04-03T00:00:00+09:00</updated><id>http://localhost:4000/2018/04/03/Iris-AI-#02</id><content type="html" xml:base="http://localhost:4000/2018/04/03/Iris-AI-02.html">&lt;p&gt;&lt;img src=&quot;https://pbs.twimg.com/profile_images/695689454300872704/Kc3D5Y6I_400x400.jpg&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ever started on a new topic of research and wondered where to start? Although the power of Google searches and forums/respositories such as Reddit and arXiv, the Information Age has presented us with a new problem: Too much information. Hundreds of tutorials, thousands of papers, all accessible online for free or a small amount of cash, it is so easy to get lost and lose track of things. Iris AI attempts to solve this problem, by creating an AI powered science assistant that personalizes in your field of interest and research. By visualizing your problem into a map of articles, it enables users to fine tune the results by using an editor for results. It is the ultimate tool to hunt down your perfect exact reading list.&lt;/p&gt;

&lt;p&gt;Started at Singularity University at NASA Ames Research Park, and based primarily in Olso, Iris AI boasts a team of 20 multinationals. Their vision, according to their website:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Iris.ai is an Artificial Intelligence that starts out as a Science Assistant; helping you find the science you need. Over time she will learn, slowly but surely becoming a Scientist herself.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;why-i-picked-iris-ai&quot;&gt;Why I picked Iris AI&lt;/h3&gt;

&lt;p&gt;Personally, I picked Iris AI because I use it. Easy as that. A few months back, I stumbled on Iris AI by reading a blog post about it. They were tech superstars, who had recently raised roughtly $2 million to support themselves. Doubling revenue every quarter in 2017, and at customer capacity, this company has some solid Scandanavian investors. Anyway, I checked out their website, created an account, and went straight ahead to using Iris. You can start by either traning or exploring, using a paper url or TED talk that Iris will analyze. So far, I mostly use the explore feature, as I just need to calibrate and tweak Iris to look for what I’m interested on.&lt;/p&gt;

&lt;p&gt;Most of my time is spent on Iris is reading the papers itself, or looking at each sub-categories, or, well, googling if there is an English version of this paper. It really saves up a lot of my time reading other blog posts, not that I don’t enjoy it or do it anyway, but for a newbie like me, not knowing where to look and start is quite discouraging. And haven’t we all fancied working for companies of products that we use on a daily basis? So there you go.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://beta.techcrunch.com/wp-content/uploads/2016/11/screen-shot-2016-11-29-at-2-57-03-pm.png?w=680&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The interview process seemed straightforward: fill in form, with application and resume, which results either in an interview with a live coding session, or well, rejection. Iris AI, is primarily based on Oslo, but it seems that they have multiple locations where they base themselves. So either their team is split, or they work from home. It is not clear about what kind of benefits they have, but I’m sure with such a rockstar team, the benefits must be immense, or work environment must be amazing, or both.&lt;/p&gt;

&lt;p&gt;They seem to have quite a number of open positions, but look for those who have a solid understanding of software coding, because most roles focus on designing software segments, planning, and then the implementation. At least, until they took the join page down. So I guess they aren’t looking for developers for now.&lt;/p&gt;

&lt;p&gt;ref:&lt;/p&gt;

&lt;p&gt;“Enterprise-focused Startups on the Rise in Nordics.” ComputerWeekly.com. Accessed April 1, 2018. https://www.computerweekly.com/news/450431516/Enterprise-focused-startups-on-the-rise-in-Nordics.&lt;/p&gt;

&lt;p&gt;“IRIS.AI Raises $2M Seed Round, Announces New AI Tokenization System.” Slush 2018. December 01, 2017. Accessed April 1, 2018. http://www.slush.org/news/iris-ai-raises-2m-seed-round-announces-new-ai-tokenization-system/.&lt;/p&gt;

&lt;p&gt;“Home – Iris.ai - Your Science Assistant.” Iris.ai - Your Science Assistant. Accessed April 2, 2018. https://iris.ai/.&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">Ever started on a new topic of research and wondered where to start? Although the power of Google searches and forums/respositories such as Reddit and arXiv, the Information Age has presented us with a new problem: Too much information. Hundreds of tutorials, thousands of papers, all accessible online for free or a small amount of cash, it is so easy to get lost and lose track of things. Iris AI attempts to solve this problem, by creating an AI powered science assistant that personalizes in your field of interest and research. By visualizing your problem into a map of articles, it enables users to fine tune the results by using an editor for results. It is the ultimate tool to hunt down your perfect exact reading list. Started at Singularity University at NASA Ames Research Park, and based primarily in Olso, Iris AI boasts a team of 20 multinationals. Their vision, according to their website: “Iris.ai is an Artificial Intelligence that starts out as a Science Assistant; helping you find the science you need. Over time she will learn, slowly but surely becoming a Scientist herself.” Why I picked Iris AI Personally, I picked Iris AI because I use it. Easy as that. A few months back, I stumbled on Iris AI by reading a blog post about it. They were tech superstars, who had recently raised roughtly $2 million to support themselves. Doubling revenue every quarter in 2017, and at customer capacity, this company has some solid Scandanavian investors. Anyway, I checked out their website, created an account, and went straight ahead to using Iris. You can start by either traning or exploring, using a paper url or TED talk that Iris will analyze. So far, I mostly use the explore feature, as I just need to calibrate and tweak Iris to look for what I’m interested on. Most of my time is spent on Iris is reading the papers itself, or looking at each sub-categories, or, well, googling if there is an English version of this paper. It really saves up a lot of my time reading other blog posts, not that I don’t enjoy it or do it anyway, but for a newbie like me, not knowing where to look and start is quite discouraging. And haven’t we all fancied working for companies of products that we use on a daily basis? So there you go. The interview process seemed straightforward: fill in form, with application and resume, which results either in an interview with a live coding session, or well, rejection. Iris AI, is primarily based on Oslo, but it seems that they have multiple locations where they base themselves. So either their team is split, or they work from home. It is not clear about what kind of benefits they have, but I’m sure with such a rockstar team, the benefits must be immense, or work environment must be amazing, or both. They seem to have quite a number of open positions, but look for those who have a solid understanding of software coding, because most roles focus on designing software segments, planning, and then the implementation. At least, until they took the join page down. So I guess they aren’t looking for developers for now. ref: “Enterprise-focused Startups on the Rise in Nordics.” ComputerWeekly.com. Accessed April 1, 2018. https://www.computerweekly.com/news/450431516/Enterprise-focused-startups-on-the-rise-in-Nordics. “IRIS.AI Raises $2M Seed Round, Announces New AI Tokenization System.” Slush 2018. December 01, 2017. Accessed April 1, 2018. http://www.slush.org/news/iris-ai-raises-2m-seed-round-announces-new-ai-tokenization-system/. “Home – Iris.ai - Your Science Assistant.” Iris.ai - Your Science Assistant. Accessed April 2, 2018. https://iris.ai/.</summary></entry><entry><title type="html">Twitter</title><link href="http://localhost:4000/2018/04/03/Twitter-03.html" rel="alternate" type="text/html" title="Twitter" /><published>2018-04-03T00:00:00+09:00</published><updated>2018-04-03T00:00:00+09:00</updated><id>http://localhost:4000/2018/04/03/Twitter-#03</id><content type="html" xml:base="http://localhost:4000/2018/04/03/Twitter-03.html">&lt;p&gt;&lt;img src=&quot;https://pbs.twimg.com/profile_images/875087697177567232/Qfy0kRIP.jpg&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction-to&quot;&gt;introduction to:&lt;/h2&gt;

&lt;p&gt;I’m sure everyone’s heard of twitter right? Hilarious and outrageous Donald Trump tweets, people asking for a year of free chicken nuggets, all sorts of shenanigans. Based on San Francisco, twitter has become one of the most iconic social networking service alongside Facebook, Instagram, and Youtube. Twitter is pretty damn famous, and chances are, if you are able to see this article, you probably either use or have heard of it at some point.&lt;/p&gt;

&lt;p&gt;Limited to only 140 characters, (which was doubled recently) users can post “tweets”, and other users can either retweet(share this), or like it. It is a massive company, ranking 21st on internet companies, with a revenue of $731 million dollars. Ok, I honestly have no idea how big that is, but you get the point. Twitter is one hell of a big company, with about 3000+ workers and more than 200 engineers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.kinja-img.com/gawker-media/image/upload/s--ilBkppfX--/c_scale,fl_progressive,q_80,w_800/vbx1bzdxkjkipmic7olv.png&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-twitter&quot;&gt;Why Twitter?&lt;/h2&gt;

&lt;p&gt;For the last company, I picked a massive company, because why the hell not? Who doesn’t want to work in one of the dream companies? But what makes Twitter more compelling is their Machine Learning team, named Cortex AI. Like most social networking services, their AI team focuses on specific important, relevant data for each user, looking to supply that usually through each users newsfeed. Or other small, helpful features that make user experience all that more seamless. For example, recently, Twitter has been training neural networks to identify and automatically crop picture previews to their most interesting part. Teaching a neural net saliency in an real life example is so much more interesting and fascinating than reading about it through a research paper. Mind you, I’m not trying to discredit all the papers or huge feats that the pioneers in the field take, but for me it really is the application of some of these technologies that completely astonish me.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“We believe in free expression and think every voice has the power to impact the world.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A lot more believable and honest statement after what Facebook has gone through with Mark Zuckerberg. Anyone can can agree that is probably true, if you have tried using Facebook. That doesn’t make one company better than the other, but it is a big change between competitors. This might result in a change in scene, but I doubt people will stop using Facebook altogether.&lt;/p&gt;

&lt;h2 id=&quot;misc&quot;&gt;misc.&lt;/h2&gt;

&lt;p&gt;Another interesting thing to note are AI chatbots. AI chatbots are starting to become common, as bot platforms embrace the new rise in AI technology. However, Microsoft released an interesting AI chatbot, that was basically a twitter bot. Basically, the more you talk to this chatbot, the smarter it becomes, learning to engage people through conversation. Unfortunately for MS, people sent the chatbot arrays of misogynistic, racist, Donald Trumpist remarks. The chatbot, being the AI is, began repeating these sentiments back, tweeting thousands of messages that were just, meh. And all of this is truly amusing, as its not like the bot had a coherent idealogy. This was all very interesting, and I’m sure to look into chat bots after this event.&lt;/p&gt;

&lt;h2 id=&quot;more-on-twitter&quot;&gt;More on Twitter&lt;/h2&gt;

&lt;p&gt;Twitter mostly makes revenue on advertisement, and probably will do just like most social networking services. Twitter is not in the top 20 IT companies, but ranks 15 on the internet companies, below Spotify and above Airbnb (ranked on revenue). To me, that is weird, as I would imagine for such a large company to rank higher. Anyway, I have heard many compliments and commendation about work environment and atmosphere from people who work there, and the general review is excellent.&lt;/p&gt;

&lt;p&gt;Twitter has a multiple interview process, again applied through using a form and recieving an email to be qualified as a candidate. It offers a myriad amount of job options, not just developer or manager jobs, and it is very interesting to note that they have very specific names for some positions, with different locations available. Job requirements are long, not really surprising. Although internship opportunities are just as unlikely, we still have to try right?&lt;/p&gt;

&lt;p&gt;ref:&lt;/p&gt;

&lt;p&gt;Bhattarai, Abha. “Trump Keeps up Twitter Assault on Amazon, This Time Criticizing Its U.S. Postal Service Contract.” The Washington Post. April 02, 2018. Accessed April 1, 2018. https://www.washingtonpost.com/news/business/wp/2018/04/02/trump-keeps-up-twitter-assault-on-amazon-this-time-criticizing-its-u-s-postal-service-contract/?utm_term=.dafa81f9e29e.&lt;/p&gt;

&lt;p&gt;Cortex. “Social Media Artificial Intelligence Content Platform Cortex.” Social Media Artificial Intelligence Content Platform Cortex. Accessed April 1, 2018. https://www.meetcortex.com/.&lt;/p&gt;

&lt;p&gt;DiPietro, Frank. “Twitter Turns to Artificial Intelligence to Build a Better User Experience.” The Motley Fool. May 27, 2017. Accessed April 1, 2018. https://www.fool.com/investing/2017/05/27/twitter-turns-to-artificial-intelligence-to-build.aspx.&lt;/p&gt;

&lt;p&gt;Isaac, Mike, and Sydney Ember. “For Election Day Influence, Twitter Ruled Social Media.” The New York Times. November 09, 2016. Accessed April 1, 2018. https://www.nytimes.com/2016/11/09/technology/for-election-day-chatter-twitter-ruled-social-media.html.&lt;/p&gt;

&lt;p&gt;Kaser, Rachel. “‘Timestamps’ Feature Makes Twitter the News Site It Was Always Meant to Be.” The Next Web. March 29, 2018. Accessed April 1, 2018. https://thenextweb.com/twitter/2018/03/30/timestamps-feature-makes-twitter-news-site-always-meant/.&lt;/p&gt;

&lt;p&gt;Spangler, Todd. “Twitter Renews MLB Deal to Live-Stream Free Weekly Games for 2018 Season.” Variety. April 03, 2018. Accessed April 1, 2018. http://variety.com/2018/digital/news/twitter-mlb-2018-live-stream-free-games-2018-1202742212/.&lt;/p&gt;

&lt;p&gt;“Twitter. It’s What’s Happening.” Twitter. Accessed April 1, 2018. https://twitter.com/.&lt;/p&gt;

&lt;p&gt;“Twitter: Number of Employees 2017 Statistic.” Statista. Accessed April 2, 2018. https://www.statista.com/statistics/272140/employees-of-twitter/.&lt;/p&gt;

&lt;p&gt;Vincent, James. “Twitter Taught Microsoft’s Friendly AI Chatbot to Be a Racist Asshole in Less than a Day.” The Verge. March 24, 2016. Accessed April 3, 2018. https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist.&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">introduction to: I’m sure everyone’s heard of twitter right? Hilarious and outrageous Donald Trump tweets, people asking for a year of free chicken nuggets, all sorts of shenanigans. Based on San Francisco, twitter has become one of the most iconic social networking service alongside Facebook, Instagram, and Youtube. Twitter is pretty damn famous, and chances are, if you are able to see this article, you probably either use or have heard of it at some point. Limited to only 140 characters, (which was doubled recently) users can post “tweets”, and other users can either retweet(share this), or like it. It is a massive company, ranking 21st on internet companies, with a revenue of $731 million dollars. Ok, I honestly have no idea how big that is, but you get the point. Twitter is one hell of a big company, with about 3000+ workers and more than 200 engineers. Why Twitter? For the last company, I picked a massive company, because why the hell not? Who doesn’t want to work in one of the dream companies? But what makes Twitter more compelling is their Machine Learning team, named Cortex AI. Like most social networking services, their AI team focuses on specific important, relevant data for each user, looking to supply that usually through each users newsfeed. Or other small, helpful features that make user experience all that more seamless. For example, recently, Twitter has been training neural networks to identify and automatically crop picture previews to their most interesting part. Teaching a neural net saliency in an real life example is so much more interesting and fascinating than reading about it through a research paper. Mind you, I’m not trying to discredit all the papers or huge feats that the pioneers in the field take, but for me it really is the application of some of these technologies that completely astonish me. “We believe in free expression and think every voice has the power to impact the world.” A lot more believable and honest statement after what Facebook has gone through with Mark Zuckerberg. Anyone can can agree that is probably true, if you have tried using Facebook. That doesn’t make one company better than the other, but it is a big change between competitors. This might result in a change in scene, but I doubt people will stop using Facebook altogether. misc. Another interesting thing to note are AI chatbots. AI chatbots are starting to become common, as bot platforms embrace the new rise in AI technology. However, Microsoft released an interesting AI chatbot, that was basically a twitter bot. Basically, the more you talk to this chatbot, the smarter it becomes, learning to engage people through conversation. Unfortunately for MS, people sent the chatbot arrays of misogynistic, racist, Donald Trumpist remarks. The chatbot, being the AI is, began repeating these sentiments back, tweeting thousands of messages that were just, meh. And all of this is truly amusing, as its not like the bot had a coherent idealogy. This was all very interesting, and I’m sure to look into chat bots after this event. More on Twitter Twitter mostly makes revenue on advertisement, and probably will do just like most social networking services. Twitter is not in the top 20 IT companies, but ranks 15 on the internet companies, below Spotify and above Airbnb (ranked on revenue). To me, that is weird, as I would imagine for such a large company to rank higher. Anyway, I have heard many compliments and commendation about work environment and atmosphere from people who work there, and the general review is excellent. Twitter has a multiple interview process, again applied through using a form and recieving an email to be qualified as a candidate. It offers a myriad amount of job options, not just developer or manager jobs, and it is very interesting to note that they have very specific names for some positions, with different locations available. Job requirements are long, not really surprising. Although internship opportunities are just as unlikely, we still have to try right? ref: Bhattarai, Abha. “Trump Keeps up Twitter Assault on Amazon, This Time Criticizing Its U.S. Postal Service Contract.” The Washington Post. April 02, 2018. Accessed April 1, 2018. https://www.washingtonpost.com/news/business/wp/2018/04/02/trump-keeps-up-twitter-assault-on-amazon-this-time-criticizing-its-u-s-postal-service-contract/?utm_term=.dafa81f9e29e. Cortex. “Social Media Artificial Intelligence Content Platform Cortex.” Social Media Artificial Intelligence Content Platform Cortex. Accessed April 1, 2018. https://www.meetcortex.com/. DiPietro, Frank. “Twitter Turns to Artificial Intelligence to Build a Better User Experience.” The Motley Fool. May 27, 2017. Accessed April 1, 2018. https://www.fool.com/investing/2017/05/27/twitter-turns-to-artificial-intelligence-to-build.aspx. Isaac, Mike, and Sydney Ember. “For Election Day Influence, Twitter Ruled Social Media.” The New York Times. November 09, 2016. Accessed April 1, 2018. https://www.nytimes.com/2016/11/09/technology/for-election-day-chatter-twitter-ruled-social-media.html. Kaser, Rachel. “‘Timestamps’ Feature Makes Twitter the News Site It Was Always Meant to Be.” The Next Web. March 29, 2018. Accessed April 1, 2018. https://thenextweb.com/twitter/2018/03/30/timestamps-feature-makes-twitter-news-site-always-meant/. Spangler, Todd. “Twitter Renews MLB Deal to Live-Stream Free Weekly Games for 2018 Season.” Variety. April 03, 2018. Accessed April 1, 2018. http://variety.com/2018/digital/news/twitter-mlb-2018-live-stream-free-games-2018-1202742212/. “Twitter. It’s What’s Happening.” Twitter. Accessed April 1, 2018. https://twitter.com/. “Twitter: Number of Employees 2017 Statistic.” Statista. Accessed April 2, 2018. https://www.statista.com/statistics/272140/employees-of-twitter/. Vincent, James. “Twitter Taught Microsoft’s Friendly AI Chatbot to Be a Racist Asshole in Less than a Day.” The Verge. March 24, 2016. Accessed April 3, 2018. https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist.</summary></entry><entry><title type="html">Narrative Science</title><link href="http://localhost:4000/2018/04/03/Narrative-Science-01.html" rel="alternate" type="text/html" title="Narrative Science" /><published>2018-04-03T00:00:00+09:00</published><updated>2018-04-03T00:00:00+09:00</updated><id>http://localhost:4000/2018/04/03/Narrative-Science-#01</id><content type="html" xml:base="http://localhost:4000/2018/04/03/Narrative-Science-01.html">&lt;p&gt;&lt;img src=&quot;https://crunchbase-production-res.cloudinary.com/image/upload/c_lpad,h_256,w_256,f_auto,q_auto:eco/v1491598621/oijmitqydmd4yv7xebi0.jpg&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Narrative Science is an NLG (natural language generation) for automating work, primarly through their platform Quill. Located in Chicago Illinois, this small but powerful startup of hundred employees is one of many competent startups in AI. With 68% of companies using AI in their product and enterprise, it is no surprise that technologies such as NLG become increasingly important.&lt;/p&gt;

&lt;p&gt;Narrative Science is a company that focuses on Natural Language Generation, which is to produce meaningful text from raw computer data. Things such as customer service, reports, and bussiness insights can all be generated and automated through the use of AI and NLG. Popular customers of Narrative Science include: MasterCard,  Deloitte, USAA and etc.&lt;/p&gt;

&lt;h3 id=&quot;why-narrative-science-is-exciting-for-me&quot;&gt;Why Narrative Science is exciting for me&lt;/h3&gt;

&lt;p&gt;I remember my first exposure to AI and ML was watching AlphaGo beat Lee Sedol in a game of the century on cable. It seemed so surreal, intangible at the time. Then came sophmore year, I was in a Hackathon competition, where me and my team wrote an app, where the user could monitor his/her house door and the app could make intelligent decisions if a person is an intrudor or not. I scratched up the basics for the backend and app the itself, (this is the start of my hatred for any mobile/web programming) in Ionic (unfortunately), as i noticed my upper classmen teammate write the object detection code. I had no idea what he was writing, until we launched the prototype! It was a YOLO (you only look once) real time object detection, and I was amazed at this thing.&lt;/p&gt;

&lt;p&gt;Fast-forward a year, the only occasional chance I get to focus on Machine Learning is by reading research papers or luckily seeing some kind of news regarding ML. In that sense, I have neved thought about how people in the industry will adopt these technologies to apply them to everyday work and bussiness. And this is why Narrative Science really hits the mark. Reading an article about it on some ML reddit post, I decided to do more research on it and was delighted to learn a bit more about how they use NLG.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://zdnet4.cbsistatic.com/hub/i/r/2014/11/28/2db80f03-76ba-11e4-b569-d4ae52e95e57/resize/770xauto/c93f325232ca51fcbbda629bd670ed31/narrativescienceflow.png&quot; alt=&quot;placeholder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is hard to find exact numbers and data on how profitable they are in the industry. They seemed to have raised quite the investment over the years, amassing roughly $43 million. Profit and other things such as revenue is hard to find the web, and even if they do exist, their sources seem questionable. Recent activities only seem to include their blog updates, with the most significant activity being their participation in “Gartner Data &amp;amp; Analytics Summit Grapevine”. Previous news are mostly announcement of investors or partners. Competitors include Yseop, Automated Insights, SAS… the list goes on.&lt;/p&gt;

&lt;p&gt;The interview process seemed straightforward: fill in form, with application and resume, which results either in an interview with a live coding session, or well, rejection. It’s very interesting that Narrative Science are proud of their benefits, as it is depicted in great detail, just like their requirements list. Joking aside, Narrative Science boast a high quality work environment, with both great physical and mental benefits. I only wish that there was more information about how the company feels like, and how it runs. Thank you for reading.&lt;/p&gt;

&lt;p&gt;reference:&lt;/p&gt;

&lt;p&gt;Press, Gil. “Top 10 Hot Artificial Intelligence (AI) Technologies.” Forbes. March 29, 2017. Accessed April 3, 2018. https://www.forbes.com/sites/gilpress/2017/01/23/top-10-hot-artificial-intelligence-ai-technologies/#2b7b4f7e1928.&lt;/p&gt;

&lt;p&gt;“Natural Language Generation Technology.” Narrative Science. Accessed April 03, 2018. https://narrativescience.com/.&lt;/p&gt;

&lt;p&gt;“Narrative Science.” Crunchbase. Accessed April 2, 2018. https://www.crunchbase.com/organization/narrative-science#section-overview.&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">Narrative Science is an NLG (natural language generation) for automating work, primarly through their platform Quill. Located in Chicago Illinois, this small but powerful startup of hundred employees is one of many competent startups in AI. With 68% of companies using AI in their product and enterprise, it is no surprise that technologies such as NLG become increasingly important. Narrative Science is a company that focuses on Natural Language Generation, which is to produce meaningful text from raw computer data. Things such as customer service, reports, and bussiness insights can all be generated and automated through the use of AI and NLG. Popular customers of Narrative Science include: MasterCard, Deloitte, USAA and etc. Why Narrative Science is exciting for me I remember my first exposure to AI and ML was watching AlphaGo beat Lee Sedol in a game of the century on cable. It seemed so surreal, intangible at the time. Then came sophmore year, I was in a Hackathon competition, where me and my team wrote an app, where the user could monitor his/her house door and the app could make intelligent decisions if a person is an intrudor or not. I scratched up the basics for the backend and app the itself, (this is the start of my hatred for any mobile/web programming) in Ionic (unfortunately), as i noticed my upper classmen teammate write the object detection code. I had no idea what he was writing, until we launched the prototype! It was a YOLO (you only look once) real time object detection, and I was amazed at this thing. Fast-forward a year, the only occasional chance I get to focus on Machine Learning is by reading research papers or luckily seeing some kind of news regarding ML. In that sense, I have neved thought about how people in the industry will adopt these technologies to apply them to everyday work and bussiness. And this is why Narrative Science really hits the mark. Reading an article about it on some ML reddit post, I decided to do more research on it and was delighted to learn a bit more about how they use NLG. It is hard to find exact numbers and data on how profitable they are in the industry. They seemed to have raised quite the investment over the years, amassing roughly $43 million. Profit and other things such as revenue is hard to find the web, and even if they do exist, their sources seem questionable. Recent activities only seem to include their blog updates, with the most significant activity being their participation in “Gartner Data &amp;amp; Analytics Summit Grapevine”. Previous news are mostly announcement of investors or partners. Competitors include Yseop, Automated Insights, SAS… the list goes on. The interview process seemed straightforward: fill in form, with application and resume, which results either in an interview with a live coding session, or well, rejection. It’s very interesting that Narrative Science are proud of their benefits, as it is depicted in great detail, just like their requirements list. Joking aside, Narrative Science boast a high quality work environment, with both great physical and mental benefits. I only wish that there was more information about how the company feels like, and how it runs. Thank you for reading. reference: Press, Gil. “Top 10 Hot Artificial Intelligence (AI) Technologies.” Forbes. March 29, 2017. Accessed April 3, 2018. https://www.forbes.com/sites/gilpress/2017/01/23/top-10-hot-artificial-intelligence-ai-technologies/#2b7b4f7e1928. “Natural Language Generation Technology.” Narrative Science. Accessed April 03, 2018. https://narrativescience.com/. “Narrative Science.” Crunchbase. Accessed April 2, 2018. https://www.crunchbase.com/organization/narrative-science#section-overview.</summary></entry><entry><title type="html">First things first</title><link href="http://localhost:4000/2018/03/13/first-things-first.html" rel="alternate" type="text/html" title="First things first" /><published>2018-03-13T00:00:00+09:00</published><updated>2018-03-13T00:00:00+09:00</updated><id>http://localhost:4000/2018/03/13/first-things-first</id><content type="html" xml:base="http://localhost:4000/2018/03/13/first-things-first.html">&lt;h3 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h3&gt;

&lt;p&gt;Github Pages, Jekyll, Hyde, and boom. Here we are. I never realized how easy it was to create a simple blog + theme and start ranting on about whatever is on my mind. Anyhow, this is my first attempt to start a blog.&lt;/p&gt;

&lt;p&gt;As someone who is an absolute rockstar in CS, with an exemplary record of destroying competitons, writing multiple industrial level bug free code, i’ll be describing about collecting annoted image description corpus for generation of rich face descriptions.&lt;/p&gt;

&lt;h2 id=&quot;just-kidding&quot;&gt;Just kidding.&lt;/h2&gt;

&lt;p&gt;Jokes aside, this blog will be mostly about simple, plain articles from your everyday layman’s perspective on computer stuff. If your looking for a tangible guide on writing an autonomous car system using the cutting edge machine learning algorithms, you’re probably at the wrong place.&lt;/p&gt;</content><author><name>Andrew Fong</name></author><summary type="html">Thoughts Github Pages, Jekyll, Hyde, and boom. Here we are. I never realized how easy it was to create a simple blog + theme and start ranting on about whatever is on my mind. Anyhow, this is my first attempt to start a blog. As someone who is an absolute rockstar in CS, with an exemplary record of destroying competitons, writing multiple industrial level bug free code, i’ll be describing about collecting annoted image description corpus for generation of rich face descriptions. Just kidding. Jokes aside, this blog will be mostly about simple, plain articles from your everyday layman’s perspective on computer stuff. If your looking for a tangible guide on writing an autonomous car system using the cutting edge machine learning algorithms, you’re probably at the wrong place.</summary></entry></feed>