<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />

  <title>
    
      The Nightly Coder &middot; for the nightly 
    
  </title>

  


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" />
  

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface" />

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/favicon.png" />
<link rel="shortcut icon" href="/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml" />

  <!-- Additional head bits without overriding original head -->
</head>


  <body class="index home">

    <div id="sidebar">
  <header>
    <h1 class="site-title">
      <a href="/">
        
        The Nightly Coder
      </a>
    </h1>
    <p class="lead">Coding for Owls and other Nocturnal creatures</p>
  </header>
  <nav id="sidebar-nav-links">
  
    <a class="home-link  active"
        href="/">Home</a>
  
  

  

  


  
    
  

  
    
  

  
    
      <a class="page-link "
          href="/about.html">About</a>
    
  

  
    
  

  
    
  

  

  
    
  

  
    
  

  
    
  

  


  


  
    
  

  
    
      <a class="category-link "
          href="/category/Resources.html">Resources</a>
    
  

  
    
  

  
    
      <a class="category-link "
          href="/category/cheatsheet.html">CheatSheets</a>
    
  

  
    
  

  

  
    
  

  
    
  

  
    
  

  


  <!-- Optional additional links to insert in sidebar nav -->
</nav>


  
    <span class="site-version">Currently v3.5.3</span>
  

  <nav id="sidebar-icon-links">
  
    <a id="github-link"
       class="icon" title="Github Project" aria-label="Github Project"
       href="https://github.com/dksehdals216">
      <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 28"><path d="M12 2c6.625 0 12 5.375 12 12 0 5.297-3.437 9.797-8.203 11.391-0.609 0.109-0.828-0.266-0.828-0.578 0-0.391 0.016-1.687 0.016-3.297 0-1.125-0.375-1.844-0.812-2.219 2.672-0.297 5.484-1.313 5.484-5.922 0-1.313-0.469-2.375-1.234-3.219 0.125-0.313 0.531-1.531-0.125-3.187-1-0.313-3.297 1.234-3.297 1.234-0.953-0.266-1.984-0.406-3-0.406s-2.047 0.141-3 0.406c0 0-2.297-1.547-3.297-1.234-0.656 1.656-0.25 2.875-0.125 3.187-0.766 0.844-1.234 1.906-1.234 3.219 0 4.594 2.797 5.625 5.469 5.922-0.344 0.313-0.656 0.844-0.766 1.609-0.688 0.313-2.438 0.844-3.484-1-0.656-1.141-1.844-1.234-1.844-1.234-1.172-0.016-0.078 0.734-0.078 0.734 0.781 0.359 1.328 1.75 1.328 1.75 0.703 2.141 4.047 1.422 4.047 1.422 0 1 0.016 1.937 0.016 2.234 0 0.313-0.219 0.688-0.828 0.578-4.766-1.594-8.203-6.094-8.203-11.391 0-6.625 5.375-12 12-12zM4.547 19.234c0.031-0.063-0.016-0.141-0.109-0.187-0.094-0.031-0.172-0.016-0.203 0.031-0.031 0.063 0.016 0.141 0.109 0.187 0.078 0.047 0.172 0.031 0.203-0.031zM5.031 19.766c0.063-0.047 0.047-0.156-0.031-0.25-0.078-0.078-0.187-0.109-0.25-0.047-0.063 0.047-0.047 0.156 0.031 0.25 0.078 0.078 0.187 0.109 0.25 0.047zM5.5 20.469c0.078-0.063 0.078-0.187 0-0.297-0.063-0.109-0.187-0.156-0.266-0.094-0.078 0.047-0.078 0.172 0 0.281s0.203 0.156 0.266 0.109zM6.156 21.125c0.063-0.063 0.031-0.203-0.063-0.297-0.109-0.109-0.25-0.125-0.313-0.047-0.078 0.063-0.047 0.203 0.063 0.297 0.109 0.109 0.25 0.125 0.313 0.047zM7.047 21.516c0.031-0.094-0.063-0.203-0.203-0.25-0.125-0.031-0.266 0.016-0.297 0.109s0.063 0.203 0.203 0.234c0.125 0.047 0.266 0 0.297-0.094zM8.031 21.594c0-0.109-0.125-0.187-0.266-0.172-0.141 0-0.25 0.078-0.25 0.172 0 0.109 0.109 0.187 0.266 0.172 0.141 0 0.25-0.078 0.25-0.172zM8.937 21.438c-0.016-0.094-0.141-0.156-0.281-0.141-0.141 0.031-0.234 0.125-0.219 0.234 0.016 0.094 0.141 0.156 0.281 0.125s0.234-0.125 0.219-0.219z"></path>
</svg>

    </a>
  

  <a id="subscribe-link"
     class="icon" title="Subscribe" aria-label="Subscribe"
     href="/feed.xml">
    <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <circle cx="6.18" cy="17.82" r="2.18"/>
    <path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/>
</svg>
  </a>

  
  
  
  

  
    <a id="tags-link"
       class="icon"
       title="Tags" aria-label="Tags"
       href="/tags.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
    </a>
  

  
    <a id="search-link"
       class="icon"
       title="Search" aria-label="Search"
       href="/search.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a>
  

  <!-- Optional additional links to insert for icons links -->
</nav>
  <p>
  &copy; 2020.
  <a href="/LICENSE.md">MIT License.</a>
</p>

</div>

    <main class="container">
      <div class="content">
  


  

  
  <article class="post-body">
    <h2 class="post-title">
      <a href="/2020/10/15/Machine-Learning-and-Audio.html">
        Machine Learning and Audio
      </a>
    </h2>
    <div class="post-meta">
  <span class="post-date">15 Oct 2020</span>
  <span class="post-categories">
    
  </span>
</div>

    
      <p>Fields:</p>

<ol>
  <li>Audio Classification
The task is essentially to extract features from the audio, and then identify which class the audio belongs to. Many useful applications pertaining to audio classification can be found in the wild – such as genre classification, instrument recognition and artist identification.</li>
</ol>

<p>A common approach to solve an audio classification task is to pre-process the audio inputs to extract useful features, and then apply a classification algorithm on it. For example, in the case study below we are given a 5 second excerpt of a sound, and the task is to identify which class does it belong to – whether it is a dog barking or a drilling sound. As mentioned in the article, an approach to deal with this is to extract an audio feature called MFCC and then pass it though a neural network to get the appropriate class.</p>

<ol>
  <li>Audio Fingerprinting
The aim of audio fingerprinting is to determine the digital “summary” of the audio. This is done to identify the audio from an audio sample. Shazam is an excellent example of an application of audio fingerprinting. It recognises the music on the basis of the first two to five seconds of a song. However, there are still situations where the system fails, especially where there is a high amount of background noise.</li>
</ol>

<p>At a high level, any machine learning problem can be divided into three types of tasks: data tasks (data collection, data cleaning, and feature formation), training (building machine learning models using data features), and evaluation (assessing the model). Features, defined as “individual measurable propert[ies] or characteristic[s] of a phenomenon being observed,” [1] are very useful because they help a machine understand the data and classify it into categories or predict a value.</p>

<p>Bishop, Christopher (2006). Pattern recognition and machine learning. Berlin: Springer. ISBN 0-387-31073-8.</p>

<p>What are audio signals?
Audio signals are signals that vibrate in the audible frequency range. When someone talks, it generates air pressure signals; the ear takes in these air pressure differences and communicates with the brain. That’s how the brain helps a person recognize that the signal is speech and understand what someone is saying.</p>

<p>Data Features &amp; Transformations
mfcc
gfcc
lpcc
pncc
pncc
entropy
Spectrum
spectral centroid
cepstrum
short-term energy
spectral flux
spectral spread
spectral rolloff
spectogram</p>

<p>Spectrum and cepstrum are two particularly important features in audio processing.
Spectrum &amp; Cepstrum:</p>

<p>Audio Signal (time domain) -&gt; Fourier Transform (sine &amp; cosine) -&gt;
Spectrum (Signal in the freq domain) -&gt; log magnitude (reduce amplitude diff) -&gt;
inverse fourier transform -&gt; cepstrum</p>

<p>Mathematically, a spectrum is the Fourier transform of a signal. A Fourier transform converts a time-domain signal to the frequency domain. In other words, a spectrum is the frequency domain representation of the input audio’s time-domain signal.</p>

<p>A cepstrum is formed by taking the log magnitude of the spectrum followed by an inverse Fourier transform. This results in a signal that’s neither in the frequency domain (because we took an inverse Fourier transform) nor in the time domain (because we took the log magnitude prior to the inverse Fourier transform). The domain of the resulting signal is called the quefrency.</p>

<p>The reason we care about the signal in the frequency domain relates to the biology of the ear. Many things must happen before we can process and interpret a sound. One happens in the cochlea, a fluid-filled part of the ear with thousands of tiny hairs that are connected to nerves. Some of the hairs are short, and some are relatively longer. The shorter hairs resonate with higher sound frequencies, and the longer hairs resonate with lower sound frequencies. Therefore, the ear is like a natural Fourier transform analyzer!</p>

<p>Another fact about human hearing is that as the sound frequency increases above 1kHz, our ears begin to get less selective to frequencies. This corresponds well with something called the Mel filter bank.</p>

<p>MFCC:
Spectrum -&gt; Mel Scale Filter bank -&gt; log magnitude -&gt; Discrete cosine Transform -&gt; MFCC feature</p>

<p>Passing a spectrum through the Mel filter bank, followed by taking the log magnitude and a discrete cosine transform (DCT) produces the Mel cepstrum. DCT extracts the signal’s main information and peaks. It is also widely used in JPEG and MPEG compressions. The peaks are the gist of the audio information. Typically, the first 13 coefficients extracted from the Mel cepstrum are called the MFCCs. These hold very useful information about audio and are often used to train machine learning models.</p>

<p>Another filter inspired by human hearing is the Gammatone filter bank. This filter bank is used as a front-end simulation of the cochlea. Thus, it has many applications in speech processing because it aims to replicate how we hear.</p>

<p>Spectrum -&gt; Gammatone filter bank -&gt; downsample and loudness compression -&gt; discrete cosine transform -&gt; GFCC feature</p>

<p>GFCCs are formed by passing the spectrum through Gammatone filter bank, followed by loudness compression and DCT. The first (approximately) 22 features are called GFCCs. GFCCs have a number of applications in speech processing, such as speaker identification.</p>

<p>Other features useful in audio processing tasks (especially speech) include LPCC, BFCC, PNCC, and spectral features like spectral flux, entropy, roll off, centroid, spread, and energy entropy.</p>


    

    
      
      
      

      
    
  </article>
  
  <article class="post-body">
    <h2 class="post-title">
      <a href="/2018/05/12/Sarcasm-Detection.html">
        Sarcasm Detection
      </a>
    </h2>
    <div class="post-meta">
  <span class="post-date">12 May 2018</span>
  <span class="post-categories">
    
  </span>
</div>

    
      <h2 id="sarcasm">Sarcasm?</h2>

<p><em>Sarcasm</em> is a linguistic phenomenon in which people state  the opposite of what they actually mean. Common in literature and in spoken words, it is the use of irony to convey one’s resentment or to mock.</p>

<p>While banter is good-humored and more of a playful conversation of sorts, sarcasm is sharp: it is meant to hurt and otherwise mock with irony.</p>

<p><img src="https://blogs.nvidia.com/wp-content/uploads/2018/01/twitter-taggedsarcasm2.png" alt="placeholder" /></p>

<h1 id="so-how-does-it-work">So how does it work?</h1>

<h2 id="its-pretty-hard">It’s pretty hard</h2>

<p>Sarcasm is definitely on the farther end of difficulty when it comes to human expression. It’s difficult for humans to understand, let alone computers. Humans are used to using tone of voice and expression, or emoticons and hashtags on social media to relay their sarcasm to their readers/listeners.</p>

<p>Another fact that makes it difficult is the use of conversational and situation context, as well as, well, common sense and general knowledge of the world. This of course, makes teaching AI unique human linguistic traits just <em> wonderfull</em>.</p>

<p>Both problems are a <strong>Classification</strong> problem. When given a piece of text as input, we want to guess if it is of sarcastic quality.</p>

<h2 id="approaches--methods">Approaches &amp; Methods</h2>

<h3 id="rule-based">Rule Based</h3>
<p>Rule-based approaches attempt to identify sarcasm through specific evidences. These evidences are captured in terms of rules that rely on indicators of sarcasm. They  use  Google  search  in  order  to  determine  how  likely  a simile is. They present a 9-step approach where at each step/rule, a simile is validated using the number of search results. A strength of this approach is that they present an
error analysis corresponding to multiple rules.</p>

<p><img src="https://image.slidesharecdn.com/cs626-sarcasmandthwarting-nov13-131115101715-phpapp02/95/sarcasm-thwarting-in-sentiment-analysis-iitbombay-30-638.jpg?cb=1384510712" alt="placeholder" /></p>

<p>Hashtags are often used by  tweet  authors  to  highlight  sarcasm,  and  hence,  if  the  sentiment  expressed  by  a
hashtag does not agree with rest of the tweet, the tweet is predicted as sarcastic.</p>

<p>The first uses a parse–based lexicon generation algorithm that creates parse trees of sentences and identifies situation phrases that bear sentiment. If a negative phrase occurs in a positive sentence, it is predicted as sarcastic.</p>

<h4 id="statistical">Statistical</h4>
<p>A variety of classifiers have been experimented for sarcasm
detection. Most work in sarcasm detection relies on SVM, with sequential minimal optimization and linear regression. Other approaches include using Chi-squared for identifying discriminating features, or Naive-Bayes combined with SVM for labeling features.</p>

<h3 id="machine-learning">Machine Learning</h3>
<p>similarity between word embeddings as features for sarcasm detection.
They augment features based on similarity of word embeddings related to most con-gruent and incongruent word pairs, and report an improvement in performance. The augmentation is key because they observe that using these features alone does not suffice.</p>

<p>Combinations of convolutional neural network,
LSTM followed by a DNN are the usual approaches taken. They compare their approach against recursive SVM, and show an improvement in case of deep learning architecture.</p>

<h2 id="history">History</h2>
<p>First paper on sarcasm detection featured in 2006, with study of lexicon indicators becoming popular the following year. 
Discovering sarcastic patterns was an early trend in sarcasm detection. Several approaches dealt with extracting patterns that are indicative of sarcasm, or carry implied sentiment. These patterns may then be used as features for a statistical classifier, or as rules in a rule-based classifier.</p>

<p><img src="https://qph.fs.quoracdn.net/main-qimg-a6aeed99e114164f365212053447cfb7-c" alt="placeholder" />
Using Twitter Hashtags as labels for twitter datasets became popular around 2013, with it being an easy label to use. This can be commonly seen in other papers, but has often problems due to complex type of sarcasm used in tweets.</p>

<h3 id="present">Present</h3>
<p>A recent trend in sarcasm detection is the use of context. The term context here refers to any information beyond the text to be predicted, and beyond common knowledge. Context may be incorporated in a variety of ways, using it as supplementary data or information from the source to improve results and learning.</p>

<h1 id="issues">Issues</h1>
<p>Sarcasm detection suffors from 3 main problems: data, feature, and classification. Although hashtag-based labeling can provide large-scale supervision, the quality of the dataset may become doubtful. This is particularly true in case of use of #not to indicate insincere sentiment.<br />
For example,</p>

<blockquote>
  <p>“I totally love bland food. #not”</p>
</blockquote>

<p>The speaker expresses sarcasm through #not. In most reported works that use hashtag-based supervision, the hashtag is removed in the pre-processing step. This reduces the sentence above to 
’I love bland food’ - which may not have a sarcastic interpretation, unless author’s context is incorporated.</p>

<p>Another feature that is often an issue is the question that can sentiment be used to detect sarcasm. The motivation behind sarcasm detection is often pointed as sarcastic sentences misleading a sentiment classifier. However, several approaches use sentiment as an input to the sarcasm classifier. It must, however, be noted that these approaches require the sentiment polarity of a sentence.</p>

<p>Sarcasm is an infrequent phenomenon of sentiment expression. This skew also reflects in datasets.</p>

<h1 id="the-future">The Future</h1>

<h3 id="coverage-of-different-forms-of-sarcasm">Coverage of different forms of sarcasm</h3>
<p>we described four species of sarcasm: propositional, lexical, like-prefixed and illocutionary sarcasm. We observe that current approaches are limited in handling the last two forms of sar-
casm:  like-prefixed  and  illocutionary.  Future  work  may  focus  on  these  forms  of sarcasm.</p>

<h3 id="culture-specific-aspects-of-sarcasm-detection">Culture-specific aspects of sarcasm detection</h3>
<p>sarcasm is closely related to language/culture-specific traits. Future approaches to sarcasm detection in new languages will benefit from understanding such traits, and  incorporating  them  into  their  classification  frameworks. show that American and Indian annotators may have substantial disagreement in their sarcasm annotations - however, this sees a non-significant degradation in the
performance of sarcasm detection
<img src="https://sg.malverninternational.com/wp-content/uploads/2017/01/languages.png" alt="placeholder" /></p>

<h3 id="deep-learning-based-architectures">Deep learning-based architectures</h3>
<p>Very few approaches have explored deep learning-based architectures so far. Future work that uses these architecture may show promise.</p>

<h2 id="related-companies">Related Companies</h2>
<p>Twitter is an obvious candidate, as are any other huge big data companies. Applications of Sarcasm Detection include: Sentiment analysis, opinion mining, and advertisement.</p>

<h3 id="related-patents">Related patents</h3>
<p>https://patents.google.com/patent/US6638217B1/en</p>

<h3 id="reference">Reference</h3>
<p>Aditya Joshi, Pushpak Bhattacharya, Mark J Carman. “Automatic Sarcasm Detection: A Survey.” IITB-Monash Research Academy, Indian Institute of Technology Bombay, Monash University. 20 Sep 2016. https://arxiv.org/pdf/1602.03426.pdf</p>

<p>Commentary. “Teaching AI How to Be Sarcastic Is Totally the Easiest Thing Ever.” Quartz. October 06, 2016. Accessed May 17, 2018. https://qz.com/801813/teaching-ai-how-to-be-sarcastic-is-totally-the-easiest-thing-ever/.</p>

<p>Komalpreet Kaur Bindra, Ankita Gupta. “Tweet Sarcasm: Mechanism of Sarcasm Detection in Twitter” PEC University of Technology, Chandigarh, India. https://pdfs.semanticscholar.org/f1a1/949aab6d40372e0a025fe8f135c220ca0ca3.pdf</p>

<p>Diana Mayndard, Mark A. Greenwood. “Who cares about sarcastic tweets? Investigating the impact of sarcasm onsentiment analysis” University of Sheffield.  https://gate.ac.uk/sale/lrec2014/arcomem/sarcasm.pdf</p>

<p>Silvio Amir, Byron C. Wallace, Hao Lyu, Paula Carvalho, Mario J. Silva. “Modelling Context with User Embeddings for Sarcasm Detection in Social Media” INESC-ID Lisboa, Instituto Superior Tecnico, Universidade de Lisboa iSchool, University of Texas at Austin. 5 Jul 2016https://arxiv.org/pdf/1607.00976.pdf</p>


    

    
      
      
      

      
    
  </article>
  
  <article class="post-body">
    <h2 class="post-title">
      <a href="/2018/05/12/NMT.html">
        Neural Machine Translation
      </a>
    </h2>
    <div class="post-meta">
  <span class="post-date">12 May 2018</span>
  <span class="post-categories">
    
  </span>
</div>

    
      <h1 id="what-is-it">What is it?</h1>

<h2 id="neural-machine-translation">Neural Machine Translation?</h2>

<p>NMT is a branch of Machine Translation (No surprises) that with is predecessor SMT (statistical machine translation, part of phrase-based engines) has become the main approach to Machine translation, being one of the most succesful areas of application of Deep Learning in Natural Language Processing.</p>

<h3 id="so-how-does-it-work">So how does it work?</h3>

<p>A NMT consists of, to dumb it down, two recurrent neural networks connected to each other, a “sequence-to-sequence”, or “encoder-to-decoder”, is often what it’s called.</p>

<p>The two networks serve as an autoencoder, which is an artificial neural network that looks to squeeze input data and then hand it over to the decoder to decompress. The goal is for the output to match the original input, allowing dimensionality reduction to happen. An encoder, like the autoencoder, will compress input sentences, but will create an internal representation to match the compression. The decoder will attempt to decipher the compressed representation, and will train using labels.</p>

<p><img src="https://image.slidesharecdn.com/briefhistoryofneuralmachinetranslation-160812133030/95/brief-history-of-neural-machine-translation-6-638.jpg?cb=1471008729" alt="placeholder" /></p>

<h1 id="research-areas">Research Areas</h1>

<h2 id="applications">Applications</h2>

<p><img src="https://lh3.googleusercontent.com/fDCN2H5TsP2PiILBb80NQoCwqiiVFnVONer3lqTjwCgdwGHgvD3GmjCLZ6Ybb5hvfmZChNFKhnU=w220-h140-e365" alt="placeholder" /></p>

<p>The easiest application of NMT that we use in everyday life is, the most popuplar translator by a long way: Google Translate. Other uses include Skype’s voice translation feature, which is a real-time speech-to-speech translation using Microsoft Translate technology as of 2017.</p>

<p>Other exciting prospects are wearable, or voice translation devices, a combination of Neural Machine Translation and other Natural Language Processing technology. These device products allow users to speak into a mic that will output into a different language, allowing people more freedom.</p>

<h1 id="history">History</h1>

<h2 id="how-it-came-to-be">How it came to be</h2>

<p>Prior to 2014, Phrase based statistical machine translation (SMT) systems and Rule-Based machine translation dominated the field. These kinds of methods were effective in creating dictionaries, or grammar programs.</p>

<p>Using mormorphological and syntactic rules and semantic analysis of both source and destination languages, RBMT relied on the linguistic aspect of the languages to translate efficiently. RBMT was weak in the sense that it had to be told explicit rules, it cannot cope with various different inputs or inputs with errors.</p>

<p>SMT on the other hand, uses statistical methods to achieve good results, but rely heavily on massive text corpus datasets, and such corpora are still rare to this day. The larger the corpus, the better the results.</p>

<h3 id="release">Release</h3>

<p>Come 2014, and the first NMT paper was published, followed by the first NMT system in a public translation competition in 2015. By 2016, Google, Microsoft, and Yandex all used NMT, which are some of the best translation software released to date.</p>

<h2 id="the-future">The Future?</h2>

<p>NMT researchers will most likely now set their focus on training langauges with scrace data; data sets as small as Romanin-English, with only 6 thousand sentances. NMT has shown that it can do extremely well given enough data, but the challenge is in the opposite: focusing on low resource languages and to overcome the limitations that come with it. Recent approaches include zero-shot learning, or applying GAN models with NMT, and etc.</p>

<h3 id="related-patents">Related Patents</h3>

<p>Neural machine translation systems with rare word processing 
https://patentimages.storage.googleapis.com/d3/f1/86/1549ed41bc5c3f/US20160117316A1.pdf</p>

<p>Using Meta-information in neural machine translation
https://patentimages.storage.googleapis.com/6b/f6/34/51557e8cd013bb/US20170323203A1.pdf</p>

<h3 id="references">References</h3>

<p>“Company Blog - One Model Is Better than Two. Yandex.Translate Launches a Hybrid Machine Translation System.” Yandex. Accessed May 17, 2018. https://yandex.com/company/blog/one-model-is-better-than-two-yu-yandex-translate-launches-a-hybrid-machine-translation-system/.</p>

<p>“A Gentle Introduction to Neural Machine Translation.” Machine Learning Mastery. November 21, 2017. Accessed May 17, 2018. https://machinelearningmastery.com/introduction-neural-machine-translation/.</p>

<p>“How Does Neural Machine Translation Work?” Learn About The Latest in Translation News Across The World. Accessed May 17, 2018. http://blog.systransoft.com/how-does-neural-machine-translation-work/.</p>

<p>“Deep Learning for Natural Language Processing (NLP): Advancements &amp; Trends.” Tryolabs Blog. December 12, 2017. Accessed May 17, 2018. https://tryolabs.com/blog/2017/12/12/deep-learning-for-nlp-advancements-and-trends-in-2017/.</p>

<p>McDaniel, Annabelle. “Neural Machine Translation for Spoken Language Domains.” SlidePlayer. July 03, 2017. Accessed May 17, 2018. http://slideplayer.com/slide/9202214/27/images/14/Neural Machine Translation (NMT).</p>

<p>Dmitry Bahdanau, KyungHyun Cho, Yoshua Bengio. “Neural Machine Translation by Jointly Learning to Align and Translate” Jacobs University Bremen, University de Montreal. 19 May 2016 https://arxiv.org/pdf/1409.0473.pdf</p>

<p>Jiatao Gu, Hany Hassan, Jacob Delvin, Victor O.K Li. “Universal Neural Machine Translation for Extremely Low Resource Languages” University of Hong Kong, Microsoft Research, Google Research. 17 apr 2018. https://arxiv.org/pdf/1802.05368.pdf</p>


    

    
      
      
      

      
    
  </article>
  
  <article class="post-body">
    <h2 class="post-title">
      <a href="/2018/05/12/Acoustic-Signal-Processing.html">
        Acoustic Signal Processing
      </a>
    </h2>
    <div class="post-meta">
  <span class="post-date">12 May 2018</span>
  <span class="post-categories">
    
  </span>
</div>

    
      <h1 id="signal-processing-introduction">Signal Processing: Introduction</h1>

<p>Signal processing refers to the acquisition, storage, display, and generation of signals – also to the extraction of information from signals and the re-encoding of information. As such, signal processing in some form is an essential element in the practice of all aspects of acoustics. Signal processing algorithms enable acousticians to separate signals from noise, to perform automatic speech recognition, or to compress information for more efficient storage or transmission.</p>

<p><img src="https://www.allaboutcircuits.com/uploads/articles/An-Introduction-to-Digital-Signal-Processing-(3).png" alt="placeholder" /></p>

<h3 id="acoustics-digital">Acoustics? Digital?</h3>

<p>Acoustics, or Audio signal processing, is intentional alteration of audio signals, electronically represented as a digital/analog form that can later be processed as signals. Before digital technology came along, analog (read continuous) signals were commonly used, in things like radio broadcasting and such. These were derived from control systems back in the 1940s and 50s.</p>

<p>However, as times changed, and computers/software more affordable, digital signals were preferred. Basic applications include: efficient storage, compression, transmission, enhancement. However, recent introduction of Neural Networks, Statistical Vector Machines, and other statistical approaches have led to more interesting aspects of application. Areas of music, speech, and environmental sounds have become the hottest topics to date.</p>

<h2 id="applications">Applications</h2>

<h4 id="classification">Classification</h4>

<p>Audio classification is a fundamental problem in the field of audio processing. The task is essentially to extract features from the audio, and then identify which class the audio belongs to. Many useful applications pertaining to audio classification can be found in the wild – such as genre classification, instrument recognition and artist identification.</p>

<p>A common approach to solve an audio classification task is to pre-process the audio inputs to extract useful features, and then apply a classification algorithm on it. For example, in the case study below we are given a 5 second excerpt of a sound, and the task is to identify which class does it belong to – whether it is a dog barking or a drilling sound. As mentioned in the article, an approach to deal with this is to extract an audio feature called MFCC and then pass it though a neural network to get the appropriate class.</p>

<h4 id="fingerprinting">Fingerprinting</h4>
<p><img src="https://icdn3.digitaltrends.com/image/shazam-app-720x720.jpg?ver=1.jpg" alt="placeholder" /></p>

<p>The aim of audio fingerprinting is to determine the digital “summary” of the audio. This is done to identify the audio from an audio sample. Shazam is an excellent example of an application of audio fingerprinting. It recognises the music on the basis of the first two to five seconds of a song. However, there are still situations where the system fails, especially where there is a high amount of background noise.</p>

<p>To solve this problem, an approach could be to represent the audio in a different manner, so that it is easily deciphered. Then, we can find out the patterns that differentiate the audio from the background noise. In the case study below, the author converts raw audio to spectrograms and then uses peak finding and fingerprint hashing algorithms to define the fingerprints of that audio file.</p>

<h4 id="music-transcription">Music Transcription</h4>

<p>Music Transcription is another challenging audio processing task. It comprises of annotating audio and creating a kind of “sheet” for generating music from it at a later point of time. The manual effort involved in transcribing music from recordings can be vast. It varies enormously depending on the complexity of the music, how good our listening skills are and how detailed we want our transcription to be.
The approach for music transcription is similar to that of speech recognition, where musical notes are transcribed into lyrical excerpts of instruments.</p>

<h2 id="related-companies">Related Companies</h2>

<p>Audio Signal processing, as part of signal processing, is essential in numerous technology, and is much common in technology today. Most of the applications are hybrids, as in they are a used in a combination with another technology as a product. An easy example would be any application that uses voice recognition software, such as Baidu, Google’s Duplex, Cortana, Alexa, etc.</p>

<h3 id="related-patents">Related Patents</h3>
<p>https://patents.google.com/patent/US9275648B2/en</p>

<h3 id="references">References</h3>

<p>Derek J. Ross, Bird Call Recognition with Artificial Neural Networks, Support Vector Machines, and Kernel Density Estimation. (Winnipeg, Canada, 2006). http://www.antiquark.com/thesis/msc-thesis-derek-ross-v5c.pdf</p>

<p>“Audio Signal Processing for Music Applications.” Coursera. Accessed May 17, 2018. https://www.coursera.org/learn/audio-signal-processing.</p>

<p>Tzanetakis, George. “George Tzanetakis.” UVic Learn to Code. Accessed May 17, 2018. http://webhome.csc.uvic.ca/~gtzan/output/.</p>

<p>Duan, Shufei, Jinglan Zhang, Paul Roe, and Michael Towsey. “A Survey of Tagging Techniques for Music, Speech and Environmental Sound.” SpringerLink. October 25, 2012. Accessed May 17, 2018. https://link.springer.com/article/10.1007/s10462-012-9362-y.</p>


    

    
      
      
      

      
    
  </article>
  
  <article class="post-body">
    <h2 class="post-title">
      <a href="/2018/04/03/Twitter-03.html">
        Twitter
      </a>
    </h2>
    <div class="post-meta">
  <span class="post-date">03 Apr 2018</span>
  <span class="post-categories">
    
  </span>
</div>

    
      <p><img src="https://pbs.twimg.com/profile_images/875087697177567232/Qfy0kRIP.jpg" alt="placeholder" /></p>

<h2 id="introduction-to">introduction to:</h2>

<p>I’m sure everyone’s heard of twitter right? Hilarious and outrageous Donald Trump tweets, people asking for a year of free chicken nuggets, all sorts of shenanigans. Based on San Francisco, twitter has become one of the most iconic social networking service alongside Facebook, Instagram, and Youtube. Twitter is pretty damn famous, and chances are, if you are able to see this article, you probably either use or have heard of it at some point.</p>

<p>Limited to only 140 characters, (which was doubled recently) users can post “tweets”, and other users can either retweet(share this), or like it. It is a massive company, ranking 21st on internet companies, with a revenue of $731 million dollars. Ok, I honestly have no idea how big that is, but you get the point. Twitter is one hell of a big company, with about 3000+ workers and more than 200 engineers.</p>

<p><img src="https://i.kinja-img.com/gawker-media/image/upload/s--ilBkppfX--/c_scale,fl_progressive,q_80,w_800/vbx1bzdxkjkipmic7olv.png" alt="placeholder" /></p>

<h2 id="why-twitter">Why Twitter?</h2>

<p>For the last company, I picked a massive company, because why the hell not? Who doesn’t want to work in one of the dream companies? But what makes Twitter more compelling is their Machine Learning team, named Cortex AI. Like most social networking services, their AI team focuses on specific important, relevant data for each user, looking to supply that usually through each users newsfeed. Or other small, helpful features that make user experience all that more seamless. For example, recently, Twitter has been training neural networks to identify and automatically crop picture previews to their most interesting part. Teaching a neural net saliency in an real life example is so much more interesting and fascinating than reading about it through a research paper. Mind you, I’m not trying to discredit all the papers or huge feats that the pioneers in the field take, but for me it really is the application of some of these technologies that completely astonish me.</p>

<blockquote>
  <p>“We believe in free expression and think every voice has the power to impact the world.”</p>
</blockquote>

<p>A lot more believable and honest statement after what Facebook has gone through with Mark Zuckerberg. Anyone can can agree that is probably true, if you have tried using Facebook. That doesn’t make one company better than the other, but it is a big change between competitors. This might result in a change in scene, but I doubt people will stop using Facebook altogether.</p>

<h2 id="misc">misc.</h2>

<p>Another interesting thing to note are AI chatbots. AI chatbots are starting to become common, as bot platforms embrace the new rise in AI technology. However, Microsoft released an interesting AI chatbot, that was basically a twitter bot. Basically, the more you talk to this chatbot, the smarter it becomes, learning to engage people through conversation. Unfortunately for MS, people sent the chatbot arrays of misogynistic, racist, Donald Trumpist remarks. The chatbot, being the AI is, began repeating these sentiments back, tweeting thousands of messages that were just, meh. And all of this is truly amusing, as its not like the bot had a coherent idealogy. This was all very interesting, and I’m sure to look into chat bots after this event.</p>

<h2 id="more-on-twitter">More on Twitter</h2>

<p>Twitter mostly makes revenue on advertisement, and probably will do just like most social networking services. Twitter is not in the top 20 IT companies, but ranks 15 on the internet companies, below Spotify and above Airbnb (ranked on revenue). To me, that is weird, as I would imagine for such a large company to rank higher. Anyway, I have heard many compliments and commendation about work environment and atmosphere from people who work there, and the general review is excellent.</p>

<p>Twitter has a multiple interview process, again applied through using a form and recieving an email to be qualified as a candidate. It offers a myriad amount of job options, not just developer or manager jobs, and it is very interesting to note that they have very specific names for some positions, with different locations available. Job requirements are long, not really surprising. Although internship opportunities are just as unlikely, we still have to try right?</p>

<p>ref:</p>

<p>Bhattarai, Abha. “Trump Keeps up Twitter Assault on Amazon, This Time Criticizing Its U.S. Postal Service Contract.” The Washington Post. April 02, 2018. Accessed April 1, 2018. https://www.washingtonpost.com/news/business/wp/2018/04/02/trump-keeps-up-twitter-assault-on-amazon-this-time-criticizing-its-u-s-postal-service-contract/?utm_term=.dafa81f9e29e.</p>

<p>Cortex. “Social Media Artificial Intelligence Content Platform Cortex.” Social Media Artificial Intelligence Content Platform Cortex. Accessed April 1, 2018. https://www.meetcortex.com/.</p>

<p>DiPietro, Frank. “Twitter Turns to Artificial Intelligence to Build a Better User Experience.” The Motley Fool. May 27, 2017. Accessed April 1, 2018. https://www.fool.com/investing/2017/05/27/twitter-turns-to-artificial-intelligence-to-build.aspx.</p>

<p>Isaac, Mike, and Sydney Ember. “For Election Day Influence, Twitter Ruled Social Media.” The New York Times. November 09, 2016. Accessed April 1, 2018. https://www.nytimes.com/2016/11/09/technology/for-election-day-chatter-twitter-ruled-social-media.html.</p>

<p>Kaser, Rachel. “‘Timestamps’ Feature Makes Twitter the News Site It Was Always Meant to Be.” The Next Web. March 29, 2018. Accessed April 1, 2018. https://thenextweb.com/twitter/2018/03/30/timestamps-feature-makes-twitter-news-site-always-meant/.</p>

<p>Spangler, Todd. “Twitter Renews MLB Deal to Live-Stream Free Weekly Games for 2018 Season.” Variety. April 03, 2018. Accessed April 1, 2018. http://variety.com/2018/digital/news/twitter-mlb-2018-live-stream-free-games-2018-1202742212/.</p>

<p>“Twitter. It’s What’s Happening.” Twitter. Accessed April 1, 2018. https://twitter.com/.</p>

<p>“Twitter: Number of Employees 2017 Statistic.” Statista. Accessed April 2, 2018. https://www.statista.com/statistics/272140/employees-of-twitter/.</p>

<p>Vincent, James. “Twitter Taught Microsoft’s Friendly AI Chatbot to Be a Racist Asshole in Less than a Day.” The Verge. March 24, 2016. Accessed April 3, 2018. https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist.</p>


    

    
      
      
      

      
    
  </article>
  

  
<div class="pagination">
  <a class="pagination-item older"
     href="/page2">
    Older
  </a>
</div>


</div>
    </main>

    <!-- Optional footer content -->

  </body>
</html>
